# backend/utils/startup_banner.py
"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Å—Ç–∞—Ä—Ç–∞–ø–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: –±–∞–Ω–Ω–µ—Ä, –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

import os
import sys
import logging
from pathlib import Path
from config.timeouts import (
    GLOBAL_REQUEST_TIMEOUT, KEEP_ALIVE_TIMEOUT, GPTQ_MODEL_LOADING_TIMEOUT,
    CHROMADB_SEARCH_TIMEOUT, GPTQ_FIRST_LOAD_TIMEOUT
)

logger = logging.getLogger(__name__)

def print_startup_banner():
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –±–∞–Ω–Ω–µ—Ä –¥–ª—è HF Spaces —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–∞–π–º–∞—É—Ç–∞—Ö –∏ React"""
    banner = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                üèõÔ∏è  Legal Assistant API v2.0 (HF Spaces)      ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  AI Legal Assistant with GPTQ Model + React Frontend        ‚ïë
‚ïë  ‚Ä¢ TheBloke/Llama-2-7B-Chat-GPTQ Integration               ‚ïë
‚ïë  ‚Ä¢ React SPA with FastAPI Backend                           ‚ïë
‚ïë  ‚Ä¢ ChromaDB Vector Search with Lazy Loading                 ‚ïë
‚ïë  ‚Ä¢ Multi-language Support (English/Ukrainian)               ‚ïë
‚ïë  ‚Ä¢ Real-time Document Processing                            ‚ïë
‚ïë  ‚Ä¢ Optimized Memory Management for HF Spaces                ‚ïë
‚ïë  üöÄ Production Ready with Graceful Degradation              ‚ïë
‚ïë  ‚è∞ Request Timeout: {GLOBAL_REQUEST_TIMEOUT}s (10 min)                     ‚ïë
‚ïë  üîÑ Keep-Alive: {KEEP_ALIVE_TIMEOUT}s                                    ‚ïë
‚ïë  ü§ñ GPTQ Loading: {GPTQ_MODEL_LOADING_TIMEOUT}s (8 min)                        ‚ïë
‚ïë  üìö ChromaDB Search: {CHROMADB_SEARCH_TIMEOUT}s                           ‚ïë
‚ïë  ‚öõÔ∏è React SPA: Enabled                                      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """
    print(banner)

def check_hf_spaces_environment():
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è HF Spaces"""
    is_hf_spaces = os.getenv("SPACE_ID") is not None
    
    print("üåç Environment Analysis:")
    print(f"   ‚Ä¢ Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local Development'}")
    
    if is_hf_spaces:
        space_id = os.getenv("SPACE_ID", "unknown")
        space_author = os.getenv("SPACE_AUTHOR", "unknown")
        print(f"   ‚Ä¢ Space ID: {space_id}")
        print(f"   ‚Ä¢ Author: {space_author}")
        print("   ü§ó HuggingFace Spaces detected - applying optimizations")
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è HF Spaces + –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã
        hf_optimizations = {
            "OLLAMA_ENABLED": "false",              # –û—Ç–∫–ª—é—á–∞–µ–º Ollama –≤ HF Spaces
            "LLM_DEMO_MODE": "false",               # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é GPTQ –º–æ–¥–µ–ª—å
            "USE_CHROMADB": "true",                 # –í–∫–ª—é—á–∞–µ–º ChromaDB
            "LOG_LEVEL": "INFO",                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ª–æ–≥–∏
            "CHROMADB_PATH": "./chromadb_data",     # –õ–æ–∫–∞–ª—å–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            "LLM_TIMEOUT": str(120),                # 2 –º–∏–Ω—É—Ç—ã timeout –¥–ª—è GPTQ inference
            "MAX_CONTEXT_DOCUMENTS": "2",          # –û–≥—Ä–∞–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞–º—è—Ç–∏
            "CONTEXT_TRUNCATE_LENGTH": "800",      # –°–æ–∫—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è HF Spaces
            "LLM_MAX_TOKENS": "400",               # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –¥–ª—è –ø–∞–º—è—Ç–∏
            "LLM_TEMPERATURE": "0.2",              # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
            "SERVE_REACT": "true",                 # –í–∫–ª—é—á–∞–µ–º React SPA
        }
        
        applied_settings = []
        for key, value in hf_optimizations.items():
            if not os.getenv(key):  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ
                os.environ[key] = value
                applied_settings.append(f"{key}={value}")
        
        if applied_settings:
            print("   ‚öôÔ∏è Applied HF Spaces optimizations:")
            for setting in applied_settings[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"      - {setting}")
            if len(applied_settings) > 5:
                print(f"      - ... and {len(applied_settings) - 5} more settings")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å –∏ —Ä–µ—Å—É—Ä—Å—ã
        _check_system_resources()
        
        print("   ‚úÖ HF Spaces environment configured with optimized timeouts")
        
    else:
        print("   üíª Local development environment")
        print(f"   ‚Ä¢ Python: {sys.version.split()[0]}")
        print(f"   ‚Ä¢ Working Dir: {os.getcwd()}")
        
        # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if not os.getenv("LLM_DEMO_MODE"):
            os.environ.setdefault("LLM_DEMO_MODE", "false")  # –†–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if not os.getenv("SERVE_REACT"):
            os.environ.setdefault("SERVE_REACT", "true")     # React –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    return is_hf_spaces

def _check_system_resources():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã"""
    try:
        import psutil
        memory = psutil.virtual_memory()
        memory_gb = memory.total // (1024**3)
        available_gb = memory.available // (1024**3)
        print(f"   üíæ Available Memory: {available_gb}GB / {memory_gb}GB")
        print(f"   üîÑ CPU Cores: {psutil.cpu_count()}")
        
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –º–∞–ª–æ –ø–∞–º—è—Ç–∏ –¥–ª—è GPTQ
        if memory_gb < 14:
            print("   ‚ö†Ô∏è Low memory detected - GPTQ model may need extended loading time")
            print(f"   ‚è∞ Extended GPTQ timeout: {GPTQ_FIRST_LOAD_TIMEOUT}s (10 min)")
        else:
            print(f"   ‚úÖ Sufficient memory for GPTQ model (standard timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s)")
            
    except ImportError:
        print("   üíæ Resource info: psutil not available")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
    try:
        import torch
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**2)
            print("   üöÄ CUDA available - GPU acceleration enabled")
            print(f"   üéØ GPU Memory: {gpu_memory}MB")
            if gpu_memory < 8000:  # –ú–µ–Ω—å—à–µ 8GB GPU
                print("   ‚ö†Ô∏è Limited GPU memory - using CPU offloading for GPTQ")
        else:
            print("   üíª CPU-only mode (normal for HF Spaces free tier)")
    except ImportError:
        print("   ‚ö†Ô∏è PyTorch not detected")

def check_critical_dependencies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å –≤–µ—Ä—Å–∏—è–º–∏ –¥–ª—è GPTQ + React"""
    print("üîç Critical Dependencies Check:")
    
    critical_deps = [
        ("fastapi", "FastAPI framework"),
        ("uvicorn", "ASGI server"),
        ("transformers", "HuggingFace Transformers (for GPTQ)"),
        ("torch", "PyTorch (for GPTQ model)")
    ]
    
    missing_critical = []
    
    for dep_name, description in critical_deps.items():
        try:
            module = __import__(dep_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"   ‚úÖ {dep_name} ({version}): {description}")
        except ImportError:
            print(f"   ‚ùå {dep_name}: {description}")
            missing_critical.append(dep_name)
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å –≤–µ—Ä—Å–∏—è–º–∏ - –í–ê–ñ–ù–´–ï –î–õ–Ø GPTQ + React
    optional_deps = [
        ("sentence_transformers", "Text embeddings (for ChromaDB)"),
        ("chromadb", "Vector database"),
        ("aiohttp", "HTTP client (for scraping)"),
        ("auto_gptq", "GPTQ quantization support (CRITICAL for GPTQ models)"),
        ("accelerate", "Model acceleration (REQUIRED for GPTQ)"),
        ("safetensors", "Safe tensor loading (REQUIRED for GPTQ)"),
        ("optimum", "HuggingFace optimization library"),
        ("psutil", "System monitoring")
    ]
    
    print("\nüì¶ Optional Dependencies (Important for GPTQ):")
    optional_available = 0
    gptq_ready = True
    
    for dep_name, description in optional_deps:
        try:
            module = __import__(dep_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"   ‚úÖ {dep_name} ({version}): {description}")
            optional_available += 1
        except ImportError:
            print(f"   ‚ö†Ô∏è {dep_name}: {description} (will use fallback)")
            if dep_name in ["auto_gptq", "accelerate", "safetensors"]:
                gptq_ready = False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º React build
    print("\n‚öõÔ∏è React Frontend Check:")
    react_build_path = Path(__file__).parent.parent.parent / "frontend" / "build"
    if react_build_path.exists():
        print(f"   ‚úÖ React build found: {react_build_path}")
        index_html = react_build_path / "index.html"
        if index_html.exists():
            print("   ‚úÖ React index.html ready")
        else:
            print("   ‚ö†Ô∏è React index.html missing")
    else:
        print(f"   ‚ö†Ô∏è React build not found: {react_build_path}")
        print("   üí° Run: cd frontend && npm run build")
    
    print(f"\nüìä Dependencies Summary:")
    print(f"   ‚Ä¢ Critical: {len(critical_deps) - len(missing_critical)}/{len(critical_deps)} available")
    print(f"   ‚Ä¢ Optional: {optional_available}/{len(optional_deps)} available")
    print(f"   ‚Ä¢ React: {'‚úÖ Ready' if react_build_path.exists() else '‚ö†Ô∏è Not built'}")
    
    if gptq_ready:
        print(f"   ü§ñ GPTQ Model Support: ‚úÖ Ready (TheBloke/Llama-2-7B-Chat-GPTQ)")
        print(f"   ‚è∞ GPTQ Loading Timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s")
    else:
        print(f"   ü§ñ GPTQ Model Support: ‚ö†Ô∏è Limited (missing auto-gptq or accelerate)")
        print(f"   ‚è∞ Fallback mode will be used")
    
    if missing_critical:
        print(f"\n‚ùå Critical dependencies missing: {', '.join(missing_critical)}")
        print("   Install with: pip install fastapi uvicorn transformers torch")
        return False
    
    print("\n‚úÖ All critical dependencies available")
    return True

def create_necessary_directories():
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —Å–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è HF Spaces + React"""
    directories = [
        "logs",
        "chromadb_data", 
        "uploads",
        "temp",
        "backups",
        ".cache",
        "offload",  # –î–ª—è model offloading –≤ HF Spaces
        "frontend/build"  # –ù–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ React –Ω–µ —Å–æ–±—Ä–∞–Ω
    ]
    
    created = []
    failed = []
    
    for directory in directories:
        try:
            os.makedirs(directory, exist_ok=True)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
            test_file = os.path.join(directory, ".test_write")
            try:
                with open(test_file, 'w') as f:
                    f.write("test")
                os.remove(test_file)
                created.append(directory)
            except:
                # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ (HF Spaces –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
                logger.warning(f"Directory {directory} created but not writable (HF Spaces limitation)")
                
        except Exception as e:
            failed.append(f"{directory}: {str(e)[:50]}")
            logger.warning(f"Could not create directory {directory}: {e}")
    
    if created:
        print(f"üìÅ Created directories: {', '.join(created)}")
    if failed:
        print(f"‚ö†Ô∏è Failed directories: {', '.join([f.split(':')[0] for f in failed])}")
    
    # –í HF Spaces –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å read-only, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    return len(created) > 0