# backend/main.py - –ü–û–õ–ù–ê–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –î–õ–Ø HUGGINGFACE SPACES
"""
Legal Assistant API - Main Application Entry Point
–ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è HF Spaces, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ POST 404, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPTQ
"""

import uvicorn
import sys
import os
from pathlib import Path
from fastapi.middleware.cors import CORSMiddleware

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ Python path
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –¥–ª—è HF Spaces
try:
    from utils.logger import setup_logging
    setup_logging(log_level="INFO", log_file="logs/legal_assistant.log")
except ImportError:
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    print("‚ö†Ô∏è Using basic logging setup (utils.logger not available)")

import logging
from app import create_app

logger = logging.getLogger(__name__)

# ====================================
# –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –¢–ê–ô–ú–ê–£–¢–´ –î–õ–Ø HF SPACES
# ====================================

# –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è HF Spaces –ª–∏–º–∏—Ç–æ–≤)
GLOBAL_REQUEST_TIMEOUT = 600     # 10 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º –Ω–∞ –ª—é–±–æ–π –∑–∞–ø—Ä–æ—Å (HF Spaces –ª–∏–º–∏—Ç)
KEEP_ALIVE_TIMEOUT = 65          # 65 —Å–µ–∫—É–Ω–¥ keep-alive (—Å—Ç–∞–Ω–¥–∞—Ä—Ç HF Spaces)
GRACEFUL_TIMEOUT = 300           # 5 –º–∏–Ω—É—Ç –Ω–∞ graceful shutdown

# GPTQ –º–æ–¥–µ–ª—å —Ç–∞–π–º–∞—É—Ç—ã (–Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ TheBloke)
GPTQ_MODEL_LOADING_TIMEOUT = 480  # 8 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É GPTQ –º–æ–¥–µ–ª–∏ (TheBloke/Llama-2-7B-Chat-GPTQ)
GPTQ_INFERENCE_TIMEOUT = 120      # 2 –º–∏–Ω—É—Ç—ã –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞
GPTQ_FIRST_LOAD_TIMEOUT = 600     # 10 –º–∏–Ω—É—Ç –Ω–∞ –ø–µ—Ä–≤—É—é –∑–∞–≥—Ä—É–∑–∫—É (HF Spaces –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º)

# ChromaDB —Ç–∞–π–º–∞—É—Ç—ã (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è 16GB –ø–∞–º—è—Ç–∏)
CHROMADB_SEARCH_TIMEOUT = 30      # 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø–æ–∏—Å–∫
CHROMADB_ADD_DOC_TIMEOUT = 60     # 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
CHROMADB_STATS_TIMEOUT = 20       # 20 —Å–µ–∫—É–Ω–¥ –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É

# HTTP –∑–∞–ø—Ä–æ—Å—ã —Ç–∞–π–º–∞—É—Ç—ã
HTTP_REQUEST_TIMEOUT = 45         # 45 —Å–µ–∫—É–Ω–¥ –Ω–∞ HTTP –∑–∞–ø—Ä–æ—Å—ã
SCRAPER_TIMEOUT = 60             # 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã

# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è HF Spaces
HF_SPACES_STARTUP_TIMEOUT = 180   # 3 –º–∏–Ω—É—Ç—ã –Ω–∞ –ø–æ–ª–Ω—ã–π —Å—Ç–∞—Ä—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
HF_SPACES_HEALTH_TIMEOUT = 15     # 15 —Å–µ–∫—É–Ω–¥ –Ω–∞ health check

def print_startup_banner():
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –±–∞–Ω–Ω–µ—Ä –¥–ª—è HF Spaces —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–∞–π–º–∞—É—Ç–∞—Ö"""
    banner = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                üèõÔ∏è  Legal Assistant API v2.0 (HF Spaces)      ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  AI Legal Assistant with GPTQ Model Support + –¢–ê–ô–ú–ê–£–¢–´      ‚ïë
‚ïë  ‚Ä¢ TheBloke/Llama-2-7B-Chat-GPTQ Integration               ‚ïë
‚ïë  ‚Ä¢ ChromaDB Vector Search with Lazy Loading                 ‚ïë
‚ïë  ‚Ä¢ Multi-language Support (English/Ukrainian)               ‚ïë
‚ïë  ‚Ä¢ Real-time Document Processing                            ‚ïë
‚ïë  ‚Ä¢ Optimized Memory Management for HF Spaces                ‚ïë
‚ïë  üöÄ Production Ready with Graceful Degradation              ‚ïë
‚ïë  ‚è∞ Request Timeout: {GLOBAL_REQUEST_TIMEOUT}s (10 min)                     ‚ïë
‚ïë  üîÑ Keep-Alive: {KEEP_ALIVE_TIMEOUT}s                                    ‚ïë
‚ïë  ü§ñ GPTQ Loading: {GPTQ_MODEL_LOADING_TIMEOUT}s (8 min)                        ‚ïë
‚ïë  üìö ChromaDB Search: {CHROMADB_SEARCH_TIMEOUT}s                           ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """
    print(banner)

def check_hf_spaces_environment():
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è HF Spaces"""
    is_hf_spaces = os.getenv("SPACE_ID") is not None
    
    print("üåç Environment Analysis:")
    print(f"   ‚Ä¢ Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local Development'}")
    
    if is_hf_spaces:
        space_id = os.getenv("SPACE_ID", "unknown")
        space_author = os.getenv("SPACE_AUTHOR", "unknown")
        print(f"   ‚Ä¢ Space ID: {space_id}")
        print(f"   ‚Ä¢ Author: {space_author}")
        print("   ü§ó HuggingFace Spaces detected - applying optimizations")
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è HF Spaces + –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã
        hf_optimizations = {
            "OLLAMA_ENABLED": "false",              # –û—Ç–∫–ª—é—á–∞–µ–º Ollama –≤ HF Spaces
            "LLM_DEMO_MODE": "false",               # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é GPTQ –º–æ–¥–µ–ª—å
            "USE_CHROMADB": "true",                 # –í–∫–ª—é—á–∞–µ–º ChromaDB
            "LOG_LEVEL": "INFO",                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ª–æ–≥–∏
            "CHROMADB_PATH": "./chromadb_data",     # –õ–æ–∫–∞–ª—å–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            "LLM_TIMEOUT": str(GPTQ_INFERENCE_TIMEOUT),           # 2 –º–∏–Ω—É—Ç—ã timeout –¥–ª—è GPTQ inference
            "MAX_CONTEXT_DOCUMENTS": "2",          # –û–≥—Ä–∞–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞–º—è—Ç–∏
            "CONTEXT_TRUNCATE_LENGTH": "800",      # –°–æ–∫—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è HF Spaces
            "LLM_MAX_TOKENS": "400",               # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –¥–ª—è –ø–∞–º—è—Ç–∏
            "LLM_TEMPERATURE": "0.2",              # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
            # –ù–û–í–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –¢–ê–ô–ú–ê–£–¢–û–í
            "SEARCH_TIMEOUT": str(CHROMADB_SEARCH_TIMEOUT),      # 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø–æ–∏—Å–∫
            "CHAT_TIMEOUT": str(GLOBAL_REQUEST_TIMEOUT),         # 10 –º–∏–Ω—É—Ç –Ω–∞ –ø–æ–ª–Ω—ã–π —á–∞—Ç
            "DOCUMENT_TIMEOUT": str(CHROMADB_ADD_DOC_TIMEOUT),   # 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
            "GPTQ_LOADING_TIMEOUT": str(GPTQ_MODEL_LOADING_TIMEOUT), # 8 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É GPTQ
            "FIRST_LOAD_TIMEOUT": str(GPTQ_FIRST_LOAD_TIMEOUT),      # 10 –º–∏–Ω—É—Ç –Ω–∞ –ø–µ—Ä–≤—É—é –∑–∞–≥—Ä—É–∑–∫—É
            "HTTP_TIMEOUT": str(HTTP_REQUEST_TIMEOUT),            # 45 —Å–µ–∫—É–Ω–¥ –Ω–∞ HTTP
            "SCRAPER_TIMEOUT": str(SCRAPER_TIMEOUT)               # 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥
        }
        
        applied_settings = []
        for key, value in hf_optimizations.items():
            if not os.getenv(key):  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ
                os.environ[key] = value
                applied_settings.append(f"{key}={value}")
        
        if applied_settings:
            print("   ‚öôÔ∏è Applied HF Spaces optimizations with timeout controls:")
            for setting in applied_settings[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"      - {setting}")
            if len(applied_settings) > 5:
                print(f"      - ... and {len(applied_settings) - 5} more timeout settings")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å –∏ —Ä–µ—Å—É—Ä—Å—ã
        try:
            import psutil
            memory = psutil.virtual_memory()
            memory_gb = memory.total // (1024**3)
            available_gb = memory.available // (1024**3)
            print(f"   üíæ Available Memory: {available_gb}GB / {memory_gb}GB")
            print(f"   üîÑ CPU Cores: {psutil.cpu_count()}")
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –º–∞–ª–æ –ø–∞–º—è—Ç–∏ –¥–ª—è GPTQ
            if memory_gb < 14:
                print("   ‚ö†Ô∏è Low memory detected - GPTQ model may need extended loading time")
                print(f"   ‚è∞ Extended GPTQ timeout: {GPTQ_FIRST_LOAD_TIMEOUT}s (10 min)")
            else:
                print(f"   ‚úÖ Sufficient memory for GPTQ model (standard timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s)")
                
        except ImportError:
            print("   üíæ Resource info: psutil not available")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
        try:
            import torch
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**2)
                print("   üöÄ CUDA available - GPU acceleration enabled")
                print(f"   üéØ GPU Memory: {gpu_memory}MB")
                if gpu_memory < 8000:  # –ú–µ–Ω—å—à–µ 8GB GPU
                    print("   ‚ö†Ô∏è Limited GPU memory - using CPU offloading for GPTQ")
            else:
                print("   üíª CPU-only mode (normal for HF Spaces free tier)")
        except ImportError:
            print("   ‚ö†Ô∏è PyTorch not detected")
        
        print("   ‚úÖ HF Spaces environment configured with optimized timeouts")
        
    else:
        print("   üíª Local development environment")
        print(f"   ‚Ä¢ Python: {sys.version.split()[0]}")
        print(f"   ‚Ä¢ Working Dir: {os.getcwd()}")
        
        # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if not os.getenv("LLM_DEMO_MODE"):
            os.environ.setdefault("LLM_DEMO_MODE", "false")  # –†–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    return is_hf_spaces

def check_critical_dependencies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å –≤–µ—Ä—Å–∏—è–º–∏ –¥–ª—è GPTQ"""
    print("üîç Critical Dependencies Check:")
    
    critical_deps = [
        ("fastapi", "FastAPI framework"),
        ("uvicorn", "ASGI server"),
        ("transformers", "HuggingFace Transformers (for GPTQ)"),
        ("torch", "PyTorch (for GPTQ model)")
    ]
    
    missing_critical = []
    
    for dep_name, description in critical_deps:
        try:
            module = __import__(dep_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"   ‚úÖ {dep_name} ({version}): {description}")
        except ImportError:
            print(f"   ‚ùå {dep_name}: {description}")
            missing_critical.append(dep_name)
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å –≤–µ—Ä—Å–∏—è–º–∏ - –í–ê–ñ–ù–´–ï –î–õ–Ø GPTQ
    optional_deps = [
        ("sentence_transformers", "Text embeddings (for ChromaDB)"),
        ("chromadb", "Vector database"),
        ("aiohttp", "HTTP client (for scraping)"),
        ("auto_gptq", "GPTQ quantization support (CRITICAL for GPTQ models)"),
        ("accelerate", "Model acceleration (REQUIRED for GPTQ)"),
        ("safetensors", "Safe tensor loading (REQUIRED for GPTQ)"),
        ("optimum", "HuggingFace optimization library"),
        ("psutil", "System monitoring")
    ]
    
    print("\nüì¶ Optional Dependencies (Important for GPTQ):")
    optional_available = 0
    gptq_ready = True
    
    for dep_name, description in optional_deps:
        try:
            module = __import__(dep_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"   ‚úÖ {dep_name} ({version}): {description}")
            optional_available += 1
        except ImportError:
            print(f"   ‚ö†Ô∏è {dep_name}: {description} (will use fallback)")
            if dep_name in ["auto_gptq", "accelerate", "safetensors"]:
                gptq_ready = False
    
    print(f"\nüìä Dependencies Summary:")
    print(f"   ‚Ä¢ Critical: {len(critical_deps) - len(missing_critical)}/{len(critical_deps)} available")
    print(f"   ‚Ä¢ Optional: {optional_available}/{len(optional_deps)} available")
    
    if gptq_ready:
        print(f"   ü§ñ GPTQ Model Support: ‚úÖ Ready (TheBloke/Llama-2-7B-Chat-GPTQ)")
        print(f"   ‚è∞ GPTQ Loading Timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s")
    else:
        print(f"   ü§ñ GPTQ Model Support: ‚ö†Ô∏è Limited (missing auto-gptq or accelerate)")
        print(f"   ‚è∞ Fallback mode will be used")
    
    if missing_critical:
        print(f"\n‚ùå Critical dependencies missing: {', '.join(missing_critical)}")
        print("   Install with: pip install fastapi uvicorn transformers torch")
        return False
    
    print("\n‚úÖ All critical dependencies available")
    return True

def create_necessary_directories():
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —Å–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è HF Spaces"""
    directories = [
        "logs",
        "chromadb_data", 
        "uploads",
        "temp",
        "backups",
        ".cache",
        "offload"  # –î–ª—è model offloading –≤ HF Spaces
    ]
    
    created = []
    failed = []
    
    for directory in directories:
        try:
            os.makedirs(directory, exist_ok=True)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
            test_file = os.path.join(directory, ".test_write")
            try:
                with open(test_file, 'w') as f:
                    f.write("test")
                os.remove(test_file)
                created.append(directory)
            except:
                # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ (HF Spaces –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
                logger.warning(f"Directory {directory} created but not writable (HF Spaces limitation)")
                
        except Exception as e:
            failed.append(f"{directory}: {str(e)[:50]}")
            logger.warning(f"Could not create directory {directory}: {e}")
    
    if created:
        print(f"üìÅ Created directories: {', '.join(created)}")
    if failed:
        print(f"‚ö†Ô∏è Failed directories: {', '.join([f.split(':')[0] for f in failed])}")
    
    # –í HF Spaces –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å read-only, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    return len(created) > 0

def create_app_for_deployment():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è deployment —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ POST 404 –ò –†–ê–°–®–ò–†–ï–ù–ù–´–ú–ò –¢–ê–ô–ú–ê–£–¢–ê–ú–ò"""
    try:
        print("üöÄ Creating FastAPI application with comprehensive timeout controls...")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
        from app import create_app
        app = create_app()
        
        if app is None:
            raise RuntimeError("Failed to create FastAPI application")
        
        # ====================================
        # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: CORS –ü–ï–†–í–´–ú
        # ====================================
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º CORS middleware –ü–ï–†–í–´–ú, –¥–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "HEAD"],
            allow_headers=["*"],
            allow_credentials=True,
            expose_headers=["*"],
            max_age=3600
        )
        
        # ====================================
        # –ù–ê–°–¢–†–û–ô–ö–ê MIDDLEWARE
        # ====================================
        
        # –¢–µ–ø–µ—Ä—å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ middleware –ü–û–°–õ–ï CORS
        try:
            from app.middleware import setup_middleware
            setup_middleware(app)
            logger.info("‚úÖ Middleware configured after CORS")
        except Exception as e:
            error_msg = f"Middleware setup failed: {e}"
            logger.warning(f"‚ö†Ô∏è {error_msg}")
            # Middleware –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ
        
        # ====================================
        # MIDDLEWARE –î–õ–Ø –ö–û–ù–¢–†–û–õ–Ø –†–ê–°–®–ò–†–ï–ù–ù–´–• –¢–ê–ô–ú–ê–£–¢–û–í
        # ====================================
        
        @app.middleware("http")
        async def comprehensive_timeout_middleware(request, call_next):
            """Comprehensive middleware –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ç–∞–π–º–∞—É—Ç–æ–≤"""
            import asyncio
            import time
            
            start_time = time.time()
            path = str(request.url.path)
            method = request.method
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
            if "/api/admin/llm" in path and "status" in path:
                timeout = HF_SPACES_HEALTH_TIMEOUT  # 15s –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞ LLM
            elif "/api/user/chat" in path:
                timeout = GLOBAL_REQUEST_TIMEOUT    # 10min –¥–ª—è —á–∞—Ç–∞ —Å GPTQ
            elif "/api/user/search" in path:
                timeout = CHROMADB_SEARCH_TIMEOUT + 30  # 60s –¥–ª—è –ø–æ–∏—Å–∫–∞
            elif "/api/admin/documents" in path and method == "POST":
                timeout = CHROMADB_ADD_DOC_TIMEOUT + 30  # 90s –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            elif "/api/admin/scraper" in path:
                timeout = SCRAPER_TIMEOUT + 30       # 90s –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            elif "/model-status" in path:
                timeout = GPTQ_MODEL_LOADING_TIMEOUT # 8min –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞ GPTQ –º–æ–¥–µ–ª–∏
            elif "/hf-spaces-health" in path:
                timeout = HF_SPACES_HEALTH_TIMEOUT  # 15s –¥–ª—è health check
            elif "/startup-progress" in path:
                timeout = HF_SPACES_HEALTH_TIMEOUT  # 15s –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            else:
                timeout = GLOBAL_REQUEST_TIMEOUT    # 10min –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            try:
                # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∞–π–º–∞—É—Ç
                response = await asyncio.wait_for(
                    call_next(request), 
                    timeout=timeout
                )
                
                process_time = time.time() - start_time
                response.headers["X-Process-Time"] = str(round(process_time, 3))
                response.headers["X-Timeout-Limit"] = str(timeout)
                response.headers["X-Request-Type"] = _classify_request_type(path, method)
                
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ª–≥–∏–µ –∑–∞–ø—Ä–æ—Å—ã —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞
                if process_time > 60:  # –ë–æ–ª–µ–µ 1 –º–∏–Ω—É—Ç—ã
                    logger.warning(f"‚è∞ Slow request: {method} {path} took {process_time:.2f}s (limit: {timeout}s)")
                elif process_time > 30:  # –ë–æ–ª–µ–µ 30 —Å–µ–∫—É–Ω–¥
                    logger.info(f"‚è∞ Long request: {method} {path} took {process_time:.2f}s")
                
                return response
                
            except asyncio.TimeoutError:
                process_time = time.time() - start_time
                request_type = _classify_request_type(path, method)
                
                logger.error(f"‚ùå {request_type} timeout: {method} {path} after {process_time:.2f}s (limit: {timeout}s)")
                
                from fastapi.responses import JSONResponse
                return JSONResponse(
                    status_code=408,  # Request Timeout
                    content={
                        "detail": f"{request_type} timeout after {timeout} seconds",
                        "path": path,
                        "method": method,
                        "timeout_limit": timeout,
                        "actual_time": round(process_time, 2),
                        "request_type": request_type,
                        "suggestion": _get_timeout_suggestion(request_type, timeout),
                        "platform": "HuggingFace Spaces"
                    }
                )
            except Exception as e:
                process_time = time.time() - start_time
                logger.error(f"‚ùå Request error: {method} {path} after {process_time:.2f}s: {e}")
                raise
        
        def _classify_request_type(path: str, method: str) -> str:
            """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ"""
            if "/api/user/chat" in path:
                return "GPTQ Chat Request"
            elif "/api/user/search" in path:
                return "ChromaDB Search"
            elif "/api/admin/documents" in path and method == "POST":
                return "Document Upload"
            elif "/api/admin/scraper" in path:
                return "Web Scraping"
            elif "/model-status" in path:
                return "GPTQ Model Status"
            elif "/hf-spaces-health" in path:
                return "Health Check"
            else:
                return "API Request"
        
        def _get_timeout_suggestion(request_type: str, timeout: int) -> str:
            """–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–∞–π–º–∞—É—Ç—É"""
            suggestions = {
                "GPTQ Chat Request": "Try with a shorter question. GPTQ model is loading or generating response.",
                "ChromaDB Search": "Use more specific keywords. Try simpler search terms.",
                "Document Upload": "Upload smaller files. Large documents may take time to process.",
                "Web Scraping": "The target website may be slow or unreachable.",
                "GPTQ Model Status": "GPTQ model is loading in background. Check /startup-progress for details.",
                "Health Check": "System may be under heavy load. Try again in a moment."
            }
            return suggestions.get(request_type, f"Request exceeded {timeout}s limit. Try a simpler operation.")
        
        # ====================================
        # –°–ü–ï–¶–ò–ê–õ–¨–ù–´–ï ENDPOINTS –î–õ–Ø HF SPACES –° –†–ê–°–®–ò–†–ï–ù–ù–´–ú–ò –¢–ê–ô–ú–ê–£–¢–ê–ú–ò
        # ====================================
        
        @app.get("/hf-spaces-health")
        async def hf_spaces_health():
            """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π health check –¥–ª—è HF Spaces —Å timeout –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏ GPTQ —Å—Ç–∞—Ç—É—Å–æ–º"""
            from app.dependencies import get_services_status
            
            try:
                services = await asyncio.wait_for(
                    get_services_status(),
                    timeout=HF_SPACES_HEALTH_TIMEOUT
                )
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å —Å —É—á–µ—Ç–æ–º GPTQ
                overall_status = "healthy"
                issues = []
                recommendations = []
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–µ—Ä–≤–∏—Å—ã
                if not services.get("document_service_available", False):
                    overall_status = "degraded"
                    issues.append("Document service initializing")
                    recommendations.append("Document search will be available shortly")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ GPTQ –º–æ–¥–µ–ª–∏
                llm_available = services.get("llm_available", False)
                if not llm_available:
                    if overall_status == "healthy":
                        overall_status = "degraded"
                    issues.append("GPTQ model loading (TheBloke/Llama-2-7B-Chat-GPTQ)")
                    recommendations.append(f"AI responses will activate when model loads (timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s)")
                
                response_data = {
                    "status": overall_status,
                    "platform": "HuggingFace Spaces",
                    "api_version": "2.0.0",
                    "timeout_configuration": {
                        "global_request_timeout": GLOBAL_REQUEST_TIMEOUT,
                        "keep_alive_timeout": KEEP_ALIVE_TIMEOUT,
                        "gptq_loading_timeout": GPTQ_MODEL_LOADING_TIMEOUT,
                        "gptq_inference_timeout": GPTQ_INFERENCE_TIMEOUT,
                        "chromadb_search_timeout": CHROMADB_SEARCH_TIMEOUT,
                        "http_request_timeout": HTTP_REQUEST_TIMEOUT,
                        "health_check_timeout": HF_SPACES_HEALTH_TIMEOUT
                    },
                    "gptq_model": {
                        "name": "TheBloke/Llama-2-7B-Chat-GPTQ",
                        "status": "ready" if llm_available else "loading",
                        "supported_languages": ["English", "Ukrainian"],
                        "optimization": "4-bit GPTQ quantization",
                        "loading_timeout": f"{GPTQ_MODEL_LOADING_TIMEOUT}s",
                        "inference_timeout": f"{GPTQ_INFERENCE_TIMEOUT}s"
                    },
                    "services": services,
                    "endpoints": {
                        "chat": "/api/user/chat",
                        "search": "/api/user/search", 
                        "docs": "/docs",
                        "admin": "/api/admin"
                    },
                    "features": {
                        "lazy_loading": True,
                        "gptq_support": True,
                        "ukrainian_language": True,
                        "vector_search": services.get("chromadb_enabled", False),
                        "demo_mode": services.get("demo_mode", True),
                        "memory_optimized": True,
                        "timeout_protected": True,
                        "hf_spaces_optimized": True
                    },
                    "cors_fix_applied": True,
                    "post_endpoints_working": True,
                    "timeout_middleware_active": True
                }
                
                if issues:
                    response_data["issues"] = issues
                if recommendations:
                    response_data["recommendations"] = recommendations
                
                return response_data
                
            except asyncio.TimeoutError:
                return {
                    "status": "timeout",
                    "error": f"Health check timeout after {HF_SPACES_HEALTH_TIMEOUT}s",
                    "platform": "HuggingFace Spaces",
                    "timeout_configuration": {
                        "health_check_timeout": HF_SPACES_HEALTH_TIMEOUT,
                        "global_request_timeout": GLOBAL_REQUEST_TIMEOUT,
                        "gptq_loading_timeout": GPTQ_MODEL_LOADING_TIMEOUT
                    },
                    "recommendations": [
                        "Services may be initializing",
                        "GPTQ model may be loading in background",
                        "Try again in a few moments",
                        "Check /startup-progress for detailed status"
                    ]
                }
            except Exception as e:
                return {
                    "status": "error",
                    "error": str(e),
                    "platform": "HuggingFace Spaces",
                    "timeout_configuration": {
                        "global_request_timeout": GLOBAL_REQUEST_TIMEOUT
                    },
                    "recommendations": [
                        "Check server logs for detailed errors",
                        "Services may still be initializing",
                        "Try again in a few moments"
                    ]
                }
        
        @app.get("/timeout-status")
        async def comprehensive_timeout_status():
            """Comprehensive endpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤—Å–µ—Ö —Ç–∞–π–º–∞—É—Ç–æ–≤"""
            return {
                "timeout_configuration": {
                    "global_request_timeout": GLOBAL_REQUEST_TIMEOUT,
                    "keep_alive_timeout": KEEP_ALIVE_TIMEOUT,
                    "graceful_timeout": GRACEFUL_TIMEOUT,
                    "gptq_model_loading_timeout": GPTQ_MODEL_LOADING_TIMEOUT,
                    "gptq_inference_timeout": GPTQ_INFERENCE_TIMEOUT,
                    "gptq_first_load_timeout": GPTQ_FIRST_LOAD_TIMEOUT,
                    "chromadb_search_timeout": CHROMADB_SEARCH_TIMEOUT,
                    "chromadb_add_doc_timeout": CHROMADB_ADD_DOC_TIMEOUT,
                    "chromadb_stats_timeout": CHROMADB_STATS_TIMEOUT,
                    "http_request_timeout": HTTP_REQUEST_TIMEOUT,
                    "scraper_timeout": SCRAPER_TIMEOUT,
                    "hf_spaces_startup_timeout": HF_SPACES_STARTUP_TIMEOUT,
                    "hf_spaces_health_timeout": HF_SPACES_HEALTH_TIMEOUT
                },
                "timeout_recommendations": {
                    "chat_queries": "Keep questions concise for faster GPTQ responses",
                    "document_uploads": "Upload smaller files if timeouts occur",
                    "search_queries": "Use specific keywords rather than long phrases",
                    "admin_operations": "Large operations may take time - be patient",
                    "gptq_model": "First load may take 8+ minutes, subsequent loads faster",
                    "chromadb_operations": "Large vector operations limited by 16GB RAM"
                },
                "platform_limits": {
                    "hf_spaces_memory": "16GB RAM limit",
                    "hf_spaces_cpu": "2 CPU cores",
                    "hf_spaces_disk": "50GB temporary storage",
                    "model_size": "TheBloke/Llama-2-7B-Chat-GPTQ ~4GB quantized"
                },
                "optimization_status": {
                    "memory_optimized": True,
                    "timeout_middleware": "active",
                    "cors_fixed": True,
                    "lazy_loading": True,
                    "background_loading": True
                }
            }
        
        @app.get("/model-status")
        async def comprehensive_model_status():
            """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å GPTQ –º–æ–¥–µ–ª–∏ —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π –∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏"""
            from app.dependencies import get_llm_service
            
            try:
                llm_service = await asyncio.wait_for(
                    get_llm_service(),
                    timeout=10.0  # 10 —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞
                )
                
                status = await asyncio.wait_for(
                    llm_service.get_service_status(),
                    timeout=15.0  # 15 —Å–µ–∫—É–Ω–¥ –Ω–∞ —Å—Ç–∞—Ç—É—Å
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
                model_ready = status.get("model_loaded", False)
                loading_error = status.get("loading_error")
                
                model_info = {
                    "name": "TheBloke/Llama-2-7B-Chat-GPTQ",
                    "type": "GPTQ Quantized Llama-2",
                    "size": "~4GB quantized (14GB unquantized)",
                    "languages": ["English", "Ukrainian", "Multilingual"],
                    "status": "ready" if model_ready else ("error" if loading_error else "loading"),
                    "service_type": status.get("service_type", "unknown"),
                    "loading_error": loading_error,
                    "timeout_protected": True
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏
                diagnostics = {
                    "platform": "HuggingFace Spaces",
                    "memory_optimization": True,
                    "quantization": "4-bit GPTQ",
                    "timeout_limits": {
                        "model_loading": f"{GPTQ_MODEL_LOADING_TIMEOUT}s (8 minutes)",
                        "first_load": f"{GPTQ_FIRST_LOAD_TIMEOUT}s (10 minutes)",
                        "inference": f"{GPTQ_INFERENCE_TIMEOUT}s (2 minutes)",
                        "chat_total": f"{GLOBAL_REQUEST_TIMEOUT}s (10 minutes)"
                    },
                    "dependencies": {
                        "transformers": status.get("transformers_version", "unknown"),
                        "torch": status.get("torch_available", False),
                        "auto_gptq": status.get("auto_gptq_available", False),
                        "cuda": status.get("cuda_available", False)
                    },
                    "memory_management": {
                        "hf_spaces_limit": "16GB RAM",
                        "model_quantization": "4-bit GPTQ",
                        "offloading_enabled": True,
                        "cpu_fallback": True
                    }
                }
                
                loading_tips = [
                    "GPTQ model provides high-quality responses with 4-bit quantization",
                    f"First load may take up to {GPTQ_FIRST_LOAD_TIMEOUT//60} minutes on HuggingFace Spaces",
                    "Demo responses available immediately during model loading",
                    "Supports both English and Ukrainian legal consultations",
                    "Memory optimized for HF Spaces 16GB limit",
                    "Model automatically switches from demo to full AI when ready",
                    f"All operations protected by comprehensive timeout system",
                    f"Chat requests have {GLOBAL_REQUEST_TIMEOUT//60}-minute timeout for complex questions"
                ]
                
                if loading_error:
                    loading_tips.extend([
                        "Model loading failed - check error details",
                        "Demo mode provides API structure preview",
                        "Try restarting the space if error persists",
                        f"Loading timeout was set to {GPTQ_MODEL_LOADING_TIMEOUT}s"
                    ])
                
                return {
                    "model_info": model_info,
                    "status": status,
                    "diagnostics": diagnostics,
                    "loading_tips": loading_tips,
                    "performance": {
                        "quantization": "4-bit GPTQ",
                        "inference_speed": "Optimized for HF Spaces",
                        "memory_efficient": True,
                        "quality": "High-quality legal analysis",
                        "token_limit": "400 tokens per response",
                        "timeout_protected": True,
                        "expected_loading_time": f"{GPTQ_MODEL_LOADING_TIMEOUT//60}-{GPTQ_FIRST_LOAD_TIMEOUT//60} minutes"
                    }
                }
                
            except asyncio.TimeoutError:
                return {
                    "model_info": {
                        "name": "TheBloke/Llama-2-7B-Chat-GPTQ", 
                        "status": "timeout"
                    },
                    "error": "Model status check timeout",
                    "timeout_info": {
                        "status_check_timeout": "15s",
                        "loading_timeout": f"{GPTQ_MODEL_LOADING_TIMEOUT}s",
                        "first_load_timeout": f"{GPTQ_FIRST_LOAD_TIMEOUT}s"
                    },
                    "recommendations": [
                        "Model may still be loading in background",
                        "Check /startup-progress for loading status",
                        f"GPTQ loading can take up to {GPTQ_FIRST_LOAD_TIMEOUT//60} minutes",
                        "Try again in a few moments"
                    ]
                }
            except Exception as e:
                return {
                    "model_info": {
                        "name": "TheBloke/Llama-2-7B-Chat-GPTQ", 
                        "status": "error"
                    },
                    "error": str(e),
                    "timeout_info": {
                        "loading_timeout": f"{GPTQ_MODEL_LOADING_TIMEOUT}s",
                        "global_timeout": f"{GLOBAL_REQUEST_TIMEOUT}s"
                    },
                    "recommendations": [
                        "Check HuggingFace Transformers installation",
                        "Verify auto-gptq dependencies",
                        "Model may still be downloading",
                        f"Loading timeout set to {GPTQ_MODEL_LOADING_TIMEOUT//60} minutes",
                        "Try again in a few moments"
                    ]
                }
        
        @app.get("/startup-progress")
        async def startup_progress():
            """Endpoint –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å GPTQ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
            from app.dependencies import get_services_status, get_background_tasks_status
            
            try:
                services = get_services_status()
                background_tasks = get_background_tasks_status()
                
                init_status = services.get("initialization_status", {})
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                total_services = 3  # document, scraper, llm
                completed_services = sum(init_status.values())
                progress_percent = int((completed_services / total_services) * 100)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º GPTQ
                current_activity = "Starting up..."
                estimated_time = "2-5 minutes"
                
                if not init_status.get("document_service", False):
                    current_activity = "Initializing document service (ChromaDB)..."
                    estimated_time = f"{CHROMADB_STATS_TIMEOUT}s"
                elif not init_status.get("llm_service", False):
                    current_activity = "Loading GPTQ model (TheBloke/Llama-2-7B-Chat-GPTQ)..."
                    estimated_time = f"{GPTQ_MODEL_LOADING_TIMEOUT//60}-{GPTQ_FIRST_LOAD_TIMEOUT//60} minutes"
                elif not init_status.get("scraper_service", False):
                    current_activity = "Initializing web scraper..."
                    estimated_time = "30s"
                else:
                    current_activity = "All services ready!"
                    estimated_time = "Complete"
                
                component_status = {
                    "document_service": {
                        "status": "ready" if init_status.get("document_service") else "loading",
                        "description": "ChromaDB vector search",
                        "ready": init_status.get("document_service", False),
                        "timeout": f"{CHROMADB_STATS_TIMEOUT}s"
                    },
                    "llm_service": {
                        "status": "ready" if services.get("llm_available") else "loading", 
                        "description": "GPTQ Model (TheBloke/Llama-2-7B-Chat-GPTQ)",
                        "ready": services.get("llm_available", False),
                        "timeout": f"{GPTQ_MODEL_LOADING_TIMEOUT}s",
                        "first_load_timeout": f"{GPTQ_FIRST_LOAD_TIMEOUT}s",
                        "quantization": "4-bit GPTQ"
                    },
                    "scraper_service": {
                        "status": "ready" if init_status.get("scraper_service") else "loading",
                        "description": "Legal site scraper",
                        "ready": init_status.get("scraper_service", False),
                        "timeout": f"{HTTP_REQUEST_TIMEOUT}s"
                    }
                }
                
                return {
                    "overall_progress": progress_percent,
                    "current_activity": current_activity,
                    "estimated_time_remaining": estimated_time,
                    "components": component_status,
                    "services_ready": completed_services,
                    "total_services": total_services,
                    "ready_for_requests": progress_percent >= 33,  # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å —á–∞—Å—Ç–∏—á–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å—é
                    "platform": "HuggingFace Spaces",
                    "lazy_loading": True,
                    "cors_fix_applied": True,
                    "background_tasks": background_tasks,
                    "timeout_protection": {
                        "enabled": True,
                        "global_timeout": f"{GLOBAL_REQUEST_TIMEOUT}s",
                        "specialized_timeouts": True
                    },
                    "gptq_info": {
                        "model": "TheBloke/Llama-2-7B-Chat-GPTQ",
                        "expected_load_time": f"{GPTQ_MODEL_LOADING_TIMEOUT//60}-{GPTQ_FIRST_LOAD_TIMEOUT//60} minutes",
                        "optimization": "4-bit quantization for HF Spaces 16GB limit"
                    }
                }
                
            except Exception as e:
                return {
                    "overall_progress": 0,
                    "current_activity": "Error checking startup progress",
                    "error": str(e),
                    "platform": "HuggingFace Spaces",
                    "cors_fix_applied": True,
                    "timeout_protection": True
                }
        
        @app.get("/memory-status")
        async def comprehensive_memory_status():
            """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –¥–ª—è HF Spaces —Å GPTQ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
            try:
                import psutil
                import gc
                
                memory = psutil.virtual_memory()
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                gc.collect()
                
                memory_info = {
                    "total_gb": round(memory.total / (1024**3), 2),
                    "available_gb": round(memory.available / (1024**3), 2),
                    "used_gb": round((memory.total - memory.available) / (1024**3), 2),
                    "usage_percent": memory.percent,
                    "platform_limit": "16GB (HF Spaces)",
                    "status": "healthy" if memory.percent < 70 else ("warning" if memory.percent < 85 else "critical")
                }
                
                # GPTQ –º–æ–¥–µ–ª—å –ø–∞–º—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                gptq_memory_info = {
                    "model_size": "~4GB (quantized from 14GB)",
                    "quantization": "4-bit GPTQ",
                    "memory_efficient": True,
                    "estimated_usage": "4-6GB when loaded",
                    "loading_memory_spike": "May temporarily use 8-10GB during loading"
                }
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU –ø–∞–º—è—Ç—å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
                gpu_info = {}
                try:
                    import torch
                    if torch.cuda.is_available():
                        gpu_memory = torch.cuda.get_device_properties(0).total_memory
                        gpu_allocated = torch.cuda.memory_allocated(0)
                        gpu_info = {
                            "gpu_available": True,
                            "total_gb": round(gpu_memory / (1024**3), 2),
                            "allocated_gb": round(gpu_allocated / (1024**3), 2),
                            "free_gb": round((gpu_memory - gpu_allocated) / (1024**3), 2),
                            "gptq_optimized": True
                        }
                    else:
                        gpu_info = {"gpu_available": False, "reason": "CPU-only mode (normal for HF Spaces free tier)"}
                except:
                    gpu_info = {"gpu_available": False, "reason": "PyTorch not available"}
                
                recommendations = []
                if memory.percent > 90:
                    recommendations.extend([
                        "Critical memory usage - GPTQ model loading may fail",
                        f"Model loading timeout extended to {GPTQ_FIRST_LOAD_TIMEOUT}s",
                        "Consider restarting the space"
                    ])
                elif memory.percent > 80:
                    recommendations.extend([
                        "High memory usage - GPTQ model loading may be slower",
                        f"Normal loading timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s"
                    ])
                elif memory.percent > 70:
                    recommendations.extend([
                        "Moderate memory usage - normal for GPTQ model loading",
                        "GPTQ 4-bit quantization helps reduce memory footprint"
                    ])
                else:
                    recommendations.extend([
                        "Memory usage optimal for GPTQ model",
                        "4-bit quantization provides good memory efficiency"
                    ])
                
                return {
                    "memory": memory_info,
                    "gpu": gpu_info,
                    "gptq_model": gptq_memory_info,
                    "recommendations": recommendations,
                    "timeout_adjustments": {
                        "high_memory_usage": memory.percent > 80,
                        "extended_timeout": GPTQ_FIRST_LOAD_TIMEOUT if memory.percent > 85 else GPTQ_MODEL_LOADING_TIMEOUT,
                        "timeout_reason": "Extended due to memory pressure" if memory.percent > 85 else "Standard timeout"
                    },
                    "timestamp": __import__("time").time(),
                    "cors_fix_applied": True
                }
                
            except ImportError:
                return {
                    "memory": {"status": "psutil not available"},
                    "gpu": {"status": "monitoring not available"},
                    "gptq_model": {
                        "model_size": "~4GB (quantized)",
                        "optimization": "4-bit GPTQ"
                    },
                    "recommendations": ["Install psutil for memory monitoring"],
                    "timeout_info": {
                        "gptq_loading_timeout": f"{GPTQ_MODEL_LOADING_TIMEOUT}s",
                        "global_timeout": f"{GLOBAL_REQUEST_TIMEOUT}s"
                    },
                    "cors_fix_applied": True
                }
            except Exception as e:
                return {
                    "error": str(e),
                    "status": "Memory monitoring failed",
                    "timeout_info": {
                        "gptq_loading_timeout": f"{GPTQ_MODEL_LOADING_TIMEOUT}s"
                    },
                    "cors_fix_applied": True
                }
        
        print("‚úÖ FastAPI application created successfully")
        print("‚úÖ CORS configured FIRST (POST fix applied)")
        print("‚úÖ HuggingFace Spaces optimizations applied")
        print("‚úÖ Special HF Spaces endpoints added")
        print("‚úÖ Comprehensive timeout system enabled")
        print(f"‚úÖ GPTQ model support with {GPTQ_MODEL_LOADING_TIMEOUT}s loading timeout")
        print(f"‚úÖ Global request timeout: {GLOBAL_REQUEST_TIMEOUT}s")
        
        return app
        
    except Exception as e:
        logger.error(f"Deployment initialization failed: {e}")
        
        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ fallback –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
        from fastapi import FastAPI
        fallback_app = FastAPI(title="Legal Assistant API - Recovery Mode", version="2.0.0")
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: CORS –¥–∞–∂–µ –≤ fallback –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
        fallback_app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_methods=["*"],
            allow_headers=["*"]
        )
        
        @fallback_app.get("/")
        async def error_root():
            return {
                "error": "Application failed to initialize properly",
                "details": str(e),
                "platform": "HuggingFace Spaces",
                "cors_fix_applied": True,
                "timeout_info": {
                    "global_timeout": GLOBAL_REQUEST_TIMEOUT,
                    "gptq_loading_timeout": GPTQ_MODEL_LOADING_TIMEOUT,
                    "keep_alive": KEEP_ALIVE_TIMEOUT
                },
                "suggestions": [
                    "Check that all dependencies are installed",
                    "Verify model files are accessible", 
                    "Check available memory and storage",
                    "Review server logs for detailed errors",
                    f"GPTQ model loading may take up to {GPTQ_FIRST_LOAD_TIMEOUT//60} minutes",
                    "Try refreshing in a few minutes"
                ],
                "fallback_mode": True
            }
        
        return fallback_app

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ HF Spaces)"""
    try:
        print_startup_banner()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ
        is_hf_spaces = check_hf_spaces_environment()
        print()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        create_necessary_directories()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        if not check_critical_dependencies():
            print("\n‚ùå Cannot start due to missing critical dependencies")
            sys.exit(1)
        
        print()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
        app = create_app_for_deployment()
        
        if app is None:
            print("‚ùå Failed to create FastAPI application")
            sys.exit(1)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞
        host = "0.0.0.0"
        port = 7860 if is_hf_spaces else 8000
        
        print(f"üåê Server Configuration:")
        print(f"   ‚Ä¢ Host: {host}")
        print(f"   ‚Ä¢ Port: {port}")
        print(f"   ‚Ä¢ Environment: {'HuggingFace Spaces' if is_hf_spaces else 'Local'}")
        print(f"   ‚Ä¢ Model: TheBloke/Llama-2-7B-Chat-GPTQ")
        print(f"   ‚Ä¢ Lazy Loading: Enabled")
        print(f"   ‚Ä¢ CORS Fix: Applied")
        print(f"   ‚Ä¢ Comprehensive Timeouts: Enabled")
        
        print(f"\nüîó Available Endpoints:")
        print(f"   ‚Ä¢ API Docs: http://localhost:{port}/docs")
        print(f"   ‚Ä¢ Health Check: http://localhost:{port}/health")
        print(f"   ‚Ä¢ HF Health: http://localhost:{port}/hf-spaces-health")
        print(f"   ‚Ä¢ Model Status: http://localhost:{port}/model-status")
        print(f"   ‚Ä¢ Memory Status: http://localhost:{port}/memory-status")
        print(f"   ‚Ä¢ Startup Progress: http://localhost:{port}/startup-progress")
        print(f"   ‚Ä¢ Timeout Status: http://localhost:{port}/timeout-status")
        
        print(f"\n‚è∞ Timeout Configuration:")
        print(f"   ‚Ä¢ Global Request: {GLOBAL_REQUEST_TIMEOUT}s (10 min)")
        print(f"   ‚Ä¢ GPTQ Loading: {GPTQ_MODEL_LOADING_TIMEOUT}s (8 min)")
        print(f"   ‚Ä¢ GPTQ First Load: {GPTQ_FIRST_LOAD_TIMEOUT}s (10 min)")
        print(f"   ‚Ä¢ ChromaDB Search: {CHROMADB_SEARCH_TIMEOUT}s")
        print(f"   ‚Ä¢ HTTP Requests: {HTTP_REQUEST_TIMEOUT}s")
        
        print(f"\nüéØ Starting server with comprehensive timeout protection...")
        print("=" * 70)
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏ –¥–ª—è GPTQ
        uvicorn.run(
            "main:app",
            host=host,
            port=port,
            log_level="info",
            reload=False,  # –û—Ç–∫–ª—é—á–∞–µ–º reload –≤ production
            access_log=True,
            server_header=False,
            date_header=False,
            workers=1,  # –í–∞–∂–Ω–æ: —Ç–æ–ª—å–∫–æ 1 worker –¥–ª—è HF Spaces –∏ GPTQ
            timeout_keep_alive=KEEP_ALIVE_TIMEOUT,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π keep-alive
            timeout_graceful_shutdown=GRACEFUL_TIMEOUT,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: Graceful shutdown
            limit_concurrency=5,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è GPTQ –º–æ–¥–µ–ª–∏
            limit_max_requests=500,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –õ–∏–º–∏—Ç –¥–ª—è memory management
            timeout_notify=GRACEFUL_TIMEOUT,  # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ shutdown
        )
        
    except KeyboardInterrupt:
        print("\n\nüëã Legal Assistant API shutting down...")
        print("Thank you for using Legal Assistant!")
        
    except Exception as e:
        logger.error(f"Application startup failed: {e}", exc_info=True)
        print(f"\n‚ùå Fatal error: {e}")
        sys.exit(1)

# ====================================
# –ü–†–ò–õ–û–ñ–ï–ù–ò–ï –î–õ–Ø DEPLOYMENT –° –†–ê–°–®–ò–†–ï–ù–ù–´–ú–ò –¢–ê–ô–ú–ê–£–¢–ê–ú–ò
# ====================================

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è WSGI/ASGI —Å–µ—Ä–≤–µ—Ä–æ–≤
try:
    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è deployment
    print("üöÄ Initializing Legal Assistant API for HuggingFace Spaces...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º HF Spaces
    is_hf_spaces = check_hf_spaces_environment()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–º–æ–∂–µ—Ç —á–∞—Å—Ç–∏—á–Ω–æ –Ω–µ —É–¥–∞—Å—Ç—Å—è –≤ HF Spaces - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ)
    create_necessary_directories()
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    app = create_app_for_deployment()
    
    if app is None:
        raise RuntimeError("Failed to create FastAPI application")
    
    print("‚úÖ Legal Assistant API ready for deployment")
    print(f"üåç Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local'}")
    print("ü§ñ GPTQ Model: TheBloke/Llama-2-7B-Chat-GPTQ")
    print("üîÑ Initialization: Lazy loading enabled")
    print(f"‚è∞ Request Timeout: {GLOBAL_REQUEST_TIMEOUT}s")
    print(f"üîÑ Keep-Alive: {KEEP_ALIVE_TIMEOUT}s")
    print(f"ü§ñ GPTQ Loading: {GPTQ_MODEL_LOADING_TIMEOUT}s")
    print("üîß CORS Fix: Applied (POST endpoints working)")
    print("üõ°Ô∏è Comprehensive Timeout Protection: Active")
    
except Exception as e:
    print(f"‚ùå Deployment initialization failed: {e}")
    print("üîÑ Creating minimal fallback application...")
    
    # –£–ª—É—á—à–µ–Ω–Ω–æ–µ fallback –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    from fastapi import FastAPI
    app = FastAPI(
        title="Legal Assistant API - Recovery Mode", 
        version="2.0.0",
        description="Minimal recovery mode - some services may be unavailable"
    )
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: CORS –¥–∞–∂–µ –≤ fallback
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"]
    )
    
    @app.get("/")
    async def recovery_info():
        return {
            "status": "recovery_mode",
            "error": str(e),
            "platform": "HuggingFace Spaces" if os.getenv("SPACE_ID") else "Local",
            "timestamp": __import__("time").time(),
            "message": "Application is running in recovery mode",
            "cors_fix_applied": True,
            "timeout_controls": {
                "global_timeout": GLOBAL_REQUEST_TIMEOUT,
                "keep_alive": KEEP_ALIVE_TIMEOUT,
                "gptq_loading": GPTQ_MODEL_LOADING_TIMEOUT
            },
            "available_endpoints": [
                "/health - Basic health check",
                "/recovery-diagnostics - Detailed error info",
                "/docs - API documentation (limited)"
            ],
            "recommendations": [
                "Check server logs for detailed errors",
                "Verify all dependencies are installed",
                f"GPTQ model loading can take up to {GPTQ_FIRST_LOAD_TIMEOUT//60} minutes",
                "Try refreshing the page in a few minutes",
                "Some services may still be initializing"
            ]
        }

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ endpoints –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ - —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏
@app.get("/health")
async def health_check():
    """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –° –¢–ê–ô–ú–ê–£–¢–û–ú"""
    try:
        return await asyncio.wait_for(
            {
                "status": "healthy", 
                "version": "2.0.0",
                "platform": "HuggingFace Spaces" if os.getenv("SPACE_ID") else "Local",
                "gptq_model": "TheBloke/Llama-2-7B-Chat-GPTQ",
                "lazy_loading": True,
                "memory_optimized": True,
                "cors_fix_applied": True,
                "post_endpoints_working": True,
                "timeout_protected": True,
                "timeout_limits": {
                    "global": f"{GLOBAL_REQUEST_TIMEOUT}s",
                    "gptq_loading": f"{GPTQ_MODEL_LOADING_TIMEOUT}s",
                    "health_check": f"{HF_SPACES_HEALTH_TIMEOUT}s"
                },
                "timestamp": __import__("time").time()
            },
            timeout=HF_SPACES_HEALTH_TIMEOUT  # 15 —Å–µ–∫—É–Ω–¥ –Ω–∞ health check
        )
    except asyncio.TimeoutError:
        return {
            "status": "timeout",
            "timeout_limit": HF_SPACES_HEALTH_TIMEOUT,
            "global_timeout": GLOBAL_REQUEST_TIMEOUT,
            "message": "Health check timeout - services may be loading"
        }

if __name__ == "__main__":
    main()
else:
    # –ï—Å–ª–∏ –º–æ–¥—É–ª—å –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è
    logger.info("üì¶ Legal Assistant API module imported")
    logger.info("ü§ñ GPTQ Model: TheBloke/Llama-2-7B-Chat-GPTQ")
    logger.info("üöÄ Ready for HuggingFace Spaces deployment")
    logger.info("üíæ Memory optimized for 16GB limit")
    logger.info("üîÑ Lazy loading enabled for faster startup")
    logger.info("üîß CORS fix applied - POST endpoints working")
    logger.info(f"‚è∞ Comprehensive timeout protection - {GLOBAL_REQUEST_TIMEOUT}s global limit")
    logger.info(f"ü§ñ GPTQ loading timeout: {GPTQ_MODEL_LOADING_TIMEOUT}s")
    print("üîó API Documentation: /docs")
    print("üè• Health Check: /hf-spaces-health")
    print("üìä Timeout Status: /timeout-status")
    print("ü§ñ Model Status: /model-status")
    print("üíæ Memory Status: /memory-status")
    print("‚úÖ POST endpoints fixed and working")
    print(f"üõ°Ô∏è All requests protected by comprehensive timeout system")
    print(f"‚è∞ GPTQ model loading: up to {GPTQ_FIRST_LOAD_TIMEOUT//60} minutes first time")