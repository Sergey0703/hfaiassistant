# backend/main.py - Ğ£ĞŸĞ ĞĞ©ĞĞĞĞĞ¯ Ğ¢ĞĞ§ĞšĞ Ğ’Ğ¥ĞĞ”Ğ
"""
Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ğº Ğ¸ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ¿ĞµÑ€ĞµÑƒÑĞ»Ğ¾Ğ¶Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğ¹ main.py Ñ startup_banner, timeout_middleware Ğ¸ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¾Ğ¹
"""

import uvicorn
import sys
import os
import logging
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ² Python path
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

# ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

def print_simple_banner():
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ±Ğ°Ğ½Ğ½ĞµÑ€ Ğ±ĞµĞ· ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¾Ğº"""
    is_hf_spaces = os.getenv("SPACE_ID") is not None
    
    banner = f"""
ğŸ›ï¸ Legal Assistant API v2.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¦™ AI Legal Assistant with Llama-3.1-8B-Instruct
âš›ï¸ React Frontend + FastAPI Backend
ğŸŒ Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local Development'}
ğŸ“š Features: Vector Search, Web Scraping, Multilingual Support
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """
    print(banner)

def create_directories():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸"""
    directories = ["logs", "chromadb_data", "uploads", "temp", "backups"]
    
    for directory in directories:
        try:
            os.makedirs(directory, exist_ok=True)
        except Exception as e:
            logger.warning(f"Could not create directory {directory}: {e}")

def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"""
    try:
        print_simple_banner()
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
        is_hf_spaces = os.getenv("SPACE_ID") is not None
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
        create_directories()
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
        app = create_app()
        
        if app is None:
            print("âŒ Failed to create FastAPI application")
            sys.exit(1)
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
        host = "0.0.0.0"
        port = 7860 if is_hf_spaces else 8000
        
        print(f"\nğŸš€ Server Configuration:")
        print(f"   â€¢ Host: {host}:{port}")
        print(f"   â€¢ Environment: {'HuggingFace Spaces' if is_hf_spaces else 'Local'}")
        print(f"   â€¢ LLM Model: Llama-3.1-8B-Instruct")
        print(f"   â€¢ API Documentation: http://localhost:{port}/docs")
        print(f"   â€¢ Health Check: http://localhost:{port}/health")
        
        if not is_hf_spaces:
            print(f"   â€¢ Main App: http://localhost:{port}/")
        
        print(f"\nğŸ¯ Starting Legal Assistant API...")
        print("=" * 70)
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑĞµÑ€Ğ²ĞµÑ€
        uvicorn.run(
            "main:app",
            host=host,
            port=port,
            log_level="info",
            reload=False,  # ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ reload Ğ² production
            access_log=True,
            workers=1,  # ĞĞ´Ğ¸Ğ½ worker Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ñ‹
            timeout_keep_alive=65,
            limit_concurrency=10,  # Ğ Ğ°Ğ·ÑƒĞ¼Ğ½Ğ¾Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ
        )
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Legal Assistant API shutting down...")
        print("Thank you for using Legal Assistant!")
        
    except Exception as e:
        logger.error(f"Application startup failed: {e}")
        print(f"\nâŒ Fatal error: {e}")
        sys.exit(1)

# ====================================
# Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• ĞŸĞ Ğ˜Ğ›ĞĞ–Ğ•ĞĞ˜Ğ¯ Ğ”Ğ›Ğ¯ DEPLOYMENT
# ====================================

try:
    print("ğŸš€ Initializing Legal Assistant API...")
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
    is_hf_spaces = os.getenv("SPACE_ID") is not None
    
    if is_hf_spaces:
        print("ğŸ¤— HuggingFace Spaces environment detected")
        
        # ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ HF Spaces
        os.environ.setdefault("USE_CHROMADB", "true")
        os.environ.setdefault("LLM_DEMO_MODE", "false")  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½ÑƒÑ Llama
        os.environ.setdefault("LOG_LEVEL", "INFO")
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
    from app import create_app
    app = create_app()
    
    if app is None:
        raise RuntimeError("Failed to create FastAPI application")
    
    print("âœ… Legal Assistant API ready for deployment")
    print(f"ğŸŒ Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local'}")
    print("ğŸ¦™ LLM Model: Llama-3.1-8B-Instruct via HuggingFace Inference API")
    print("âš›ï¸ React Frontend: Integrated")
    print("ğŸ“š Vector Search: ChromaDB enabled")
    print("ğŸŒ Web Scraping: Available")
    print("ğŸ”„ Simple initialization: No background tasks")
    
except Exception as e:
    print(f"âŒ Deployment initialization failed: {e}")
    print("ğŸ”„ Creating minimal fallback application...")
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ fallback Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
    from fastapi import FastAPI
    from fastapi.middleware.cors import CORSMiddleware
    
    app = FastAPI(
        title="Legal Assistant API - Minimal Mode", 
        version="2.0.0",
        description="Minimal mode - some services may be unavailable"
    )
    
    # CORS Ğ´Ğ°Ğ¶Ğµ Ğ² fallback
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"]
    )
    
    @app.get("/")
    async def minimal_root():
        return {
            "status": "minimal_mode",
            "error": str(e),
            "message": "Application running in minimal mode",
            "available_endpoints": ["/docs", "/health"],
            "recommendations": [
                "Check that all dependencies are installed",
                "Verify all Python modules are present",
                "Check server logs for detailed errors"
            ]
        }
    
    @app.get("/health")
    async def minimal_health():
        return {
            "status": "minimal",
            "error": str(e),
            "timestamp": __import__("time").time(),
            "message": "Application started in minimal mode"
        }
    
    print("âœ… Minimal fallback application created")

# ====================================
# ĞĞ¡ĞĞĞ’ĞĞ«Ğ• ENDPOINTS (ĞµÑĞ»Ğ¸ API Ñ€Ğ¾ÑƒÑ‚Ñ‹ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ğ»Ğ¸ÑÑŒ)
# ====================================

try:
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ñƒ Ğ½Ğ°Ñ ĞµÑÑ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ endpoints
    from fastapi.responses import JSONResponse
    
    @app.get("/api-info")
    async def api_info():
        """Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± API (fallback endpoint)"""
        return {
            "api": "Legal Assistant API v2.0",
            "llm_model": "Llama-3.1-8B-Instruct",
            "status": "running",
            "features": {
                "llama_integration": True,
                "vector_search": True,
                "web_scraping": True,
                "react_frontend": True,
                "multilingual": True
            },
            "endpoints": {
                "documentation": "/docs",
                "health_check": "/health",
                "api_status": "/api-status"
            },
            "platform": "HuggingFace Spaces" if os.getenv("SPACE_ID") else "Local",
            "simplified_architecture": True
        }
    
    @app.get("/llama-status")
    async def llama_status():
        """Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Llama Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
        try:
            from app.dependencies import get_llm_service
            llm_service = get_llm_service()
            status = await llm_service.get_service_status()
            
            return {
                "llama_model": "meta-llama/Llama-3.1-8B-Instruct",
                "service_ready": status.get("ready", False),
                "service_type": status.get("service_type", "unknown"),
                "hf_token_configured": status.get("hf_token_configured", False),
                "supported_languages": ["en", "uk"],
                "features": {
                    "legal_qa": True,
                    "document_analysis": True,
                    "multilingual": True,
                    "context_aware": True
                },
                "inference_method": "HuggingFace Inference API",
                "recommendations": status.get("recommendations", [])
            }
        except Exception as e:
            return JSONResponse(
                status_code=503,
                content={
                    "llama_model": "meta-llama/Llama-3.1-8B-Instruct",
                    "service_ready": False,
                    "error": str(e),
                    "message": "Llama service initialization failed"
                }
            )

except Exception as endpoint_error:
    print(f"âš ï¸ Could not add info endpoints: {endpoint_error}")

# ====================================
# Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ¯ Ğ”Ğ˜ĞĞ“ĞĞĞ¡Ğ¢Ğ˜ĞšĞ
# ====================================

if __name__ == "__main__":
    main()
else:
    # ĞšĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ (deployment)
    logger.info("ğŸ“¦ Legal Assistant API module imported")
    logger.info("ğŸ¦™ LLM Model: Llama-3.1-8B-Instruct")
    logger.info("âš›ï¸ React SPA: Integrated fullstack application")
    logger.info("ğŸš€ Ready for deployment")
    logger.info("ğŸ’¡ Simplified architecture - no background tasks")
    
    print("ğŸ”— Available endpoints:")
    print("   â€¢ Main App: /")
    print("   â€¢ API Documentation: /docs")
    print("   â€¢ Health Check: /health")
    print("   â€¢ API Status: /api-status")
    print("   â€¢ Llama Status: /llama-status")
    print("   â€¢ Chat API: /api/user/chat")
    print("   â€¢ Search API: /api/user/search")
    print("   â€¢ Admin Panel: /api/admin")
    
    print("âœ… Simplified Legal Assistant API ready")
    print("ğŸ¦™ Llama-3.1-8B-Instruct integration active")
    print("âš¡ Fast startup - no complex background loading")