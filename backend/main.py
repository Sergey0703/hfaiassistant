# backend/main.py - ĞœĞ˜ĞĞ˜ĞœĞĞ›Ğ¬ĞĞĞ¯ Ğ¢ĞĞ§ĞšĞ Ğ’Ğ¥ĞĞ”Ğ
"""
Ğ£Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹
Ğ£Ğ±Ñ€Ğ°Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ğ°Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°, Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
"""

import uvicorn
import sys
import os
import logging
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ² Python path
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

# ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

def print_minimal_banner():
    """ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±Ğ°Ğ½Ğ½ĞµÑ€ Ğ´Ğ»Ñ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹"""
    is_hf_spaces = os.getenv("SPACE_ID") is not None
    
    banner = f"""
ğŸ›ï¸ Minimal Legal RAG System v1.0
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– FLAN-T5 Small + Sentence Transformers + ChromaDB
âš¡ Target: <1GB RAM, Fast startup, HuggingFace Spaces optimized
ğŸŒ Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local Development'}
ğŸ“š Features: Semantic Search, Document Upload, Multilingual Support
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """
    print(banner)

def create_directories():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸"""
    directories = ["logs", "chromadb_data", "uploads", "temp", ".cache"]
    
    for directory in directories:
        try:
            os.makedirs(directory, exist_ok=True)
        except Exception as e:
            logger.warning(f"Could not create directory {directory}: {e}")

def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"""
    try:
        print_minimal_banner()
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
        is_hf_spaces = os.getenv("SPACE_ID") is not None
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
        create_directories()
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
        app = create_app()
        
        if app is None:
            print("âŒ Failed to create FastAPI application")
            sys.exit(1)
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
        host = "0.0.0.0"
        port = 7860 if is_hf_spaces else 8000
        
        print(f"\nğŸš€ Minimal RAG Configuration:")
        print(f"   â€¢ Host: {host}:{port}")
        print(f"   â€¢ Environment: {'HuggingFace Spaces' if is_hf_spaces else 'Local'}")
        print(f"   â€¢ LLM Model: google/flan-t5-small (~300 MB)")
        print(f"   â€¢ Embedding: all-MiniLM-L6-v2 (~90 MB)")
        print(f"   â€¢ Vector DB: ChromaDB")
        print(f"   â€¢ Total RAM: ~920 MB target")
        print(f"   â€¢ API Documentation: http://localhost:{port}/docs")
        print(f"   â€¢ Health Check: http://localhost:{port}/health")
        
        if not is_hf_spaces:
            print(f"   â€¢ Main App: http://localhost:{port}/")
        
        print(f"\nâš¡ Starting Minimal RAG System...")
        print("=" * 50)
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑĞµÑ€Ğ²ĞµÑ€
        uvicorn.run(
            "main:app",
            host=host,
            port=port,
            log_level="info",
            reload=False,
            access_log=True,
            workers=1,
            timeout_keep_alive=30,  # ĞœĞµĞ½ÑŒÑˆĞµ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
            limit_concurrency=5,    # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
        )
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Minimal RAG System shutting down...")
        print("Thank you for using Minimal RAG!")
        
    except Exception as e:
        logger.error(f"Application startup failed: {e}")
        print(f"\nâŒ Fatal error: {e}")
        sys.exit(1)

# ====================================
# Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• ĞŸĞ Ğ˜Ğ›ĞĞ–Ğ•ĞĞ˜Ğ¯ Ğ”Ğ›Ğ¯ DEPLOYMENT
# ====================================

try:
    print("ğŸš€ Initializing Minimal RAG System...")
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
    is_hf_spaces = os.getenv("SPACE_ID") is not None
    
    if is_hf_spaces:
        print("ğŸ¤— HuggingFace Spaces environment detected")
        
        # ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ HF Spaces
        os.environ.setdefault("USE_CHROMADB", "true")
        os.environ.setdefault("LOG_LEVEL", "INFO")
        os.environ.setdefault("LLM_MODEL", "google/flan-t5-small")
        os.environ.setdefault("LLM_MAX_TOKENS", "150")
        os.environ.setdefault("LLM_TIMEOUT", "20")
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
    from app import create_app
    app = create_app()
    
    if app is None:
        raise RuntimeError("Failed to create FastAPI application")
    
    print("âœ… Minimal RAG System ready for deployment")
    print(f"ğŸŒ Platform: {'HuggingFace Spaces' if is_hf_spaces else 'Local'}")
    print("ğŸ¤– LLM Model: google/flan-t5-small")
    print("ğŸ” Embedding: sentence-transformers/all-MiniLM-L6-v2")
    print("ğŸ“Š Vector DB: ChromaDB")
    print("âš›ï¸ React Frontend: Integrated")
    print("ğŸ’¾ Memory Target: <1GB RAM")
    print("âš¡ Fast startup: No heavy models")
    
except Exception as e:
    print(f"âŒ Deployment initialization failed: {e}")
    print("ğŸ”„ Creating minimal fallback application...")
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ fallback Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
    from fastapi import FastAPI
    from fastapi.middleware.cors import CORSMiddleware
    
    app = FastAPI(
        title="Minimal RAG System - Fallback Mode", 
        version="1.0.0",
        description="Minimal mode - some services may be unavailable"
    )
    
    # CORS Ğ´Ğ°Ğ¶Ğµ Ğ² fallback
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"]
    )
    
    @app.get("/")
    async def minimal_root():
        return {
            "status": "minimal_mode",
            "error": str(e),
            "message": "Application running in minimal mode",
            "model": "google/flan-t5-small",
            "target_memory": "<1GB RAM",
            "available_endpoints": ["/docs", "/health"],
            "recommendations": [
                "Check that transformers is installed",
                "Verify sentence-transformers availability", 
                "Check server logs for detailed errors"
            ]
        }
    
    @app.get("/health")
    async def minimal_health():
        return {
            "status": "minimal",
            "error": str(e),
            "timestamp": __import__("time").time(),
            "message": "Application started in minimal mode"
        }
    
    print("âœ… Minimal fallback application created")

# ====================================
# ĞĞ¡ĞĞĞ’ĞĞ«Ğ• ENDPOINTS (ĞµÑĞ»Ğ¸ API Ñ€Ğ¾ÑƒÑ‚Ñ‹ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ğ»Ğ¸ÑÑŒ)
# ====================================

try:
    @app.get("/api-info")
    async def api_info():
        """Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± API"""
        return {
            "api": "Minimal RAG System v1.0",
            "llm_model": "google/flan-t5-small",
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
            "vector_db": "ChromaDB",
            "status": "running",
            "memory_target": "<1GB RAM",
            "features": {
                "flan_t5_integration": True,
                "semantic_search": True,
                "document_upload": True,
                "multilingual": True,
                "fast_startup": True
            },
            "endpoints": {
                "documentation": "/docs",
                "health_check": "/health",
                "api_status": "/api-status"
            },
            "platform": "HuggingFace Spaces" if os.getenv("SPACE_ID") else "Local"
        }
    
    @app.get("/model-status")
    async def model_status():
        """Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"""
        try:
            from app.dependencies import get_llm_service
            llm_service = get_llm_service()
            status = await llm_service.get_service_status()
            
            return {
                "llm_model": "google/flan-t5-small",
                "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
                "llm_ready": status.get("ready", False),
                "llm_type": status.get("service_type", "unknown"),
                "memory_estimate": {
                    "flan_t5": "~300 MB",
                    "embeddings": "~90 MB", 
                    "chromadb": "~20 MB",
                    "total": "~920 MB"
                },
                "features": {
                    "text2text_generation": True,
                    "semantic_embeddings": True,
                    "vector_search": True,
                    "multilingual": True
                }
            }
        except Exception as e:
            return {
                "llm_model": "google/flan-t5-small",
                "embedding_model": "sentence-transformers/all-MiniLM-L6-v2", 
                "llm_ready": False,
                "error": str(e),
                "message": "Model services initialization failed"
            }

except Exception as endpoint_error:
    print(f"âš ï¸ Could not add info endpoints: {endpoint_error}")

# ====================================
# Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ¯ Ğ”Ğ˜ĞĞ“ĞĞĞ¡Ğ¢Ğ˜ĞšĞ
# ====================================

if __name__ == "__main__":
    main()
else:
    # ĞšĞ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ (deployment)
    logger.info("ğŸ“¦ Minimal RAG System module imported")
    logger.info("ğŸ¤– LLM Model: google/flan-t5-small")
    logger.info("ğŸ” Embedding Model: sentence-transformers/all-MiniLM-L6-v2")
    logger.info("ğŸ’¾ Memory Target: <1GB RAM")
    logger.info("âš¡ Fast startup enabled")
    
    print("ğŸ”— Available endpoints:")
    print("   â€¢ Main App: /")
    print("   â€¢ API Documentation: /docs")
    print("   â€¢ Health Check: /health")
    print("   â€¢ API Status: /api-status")
    print("   â€¢ Model Status: /model-status")
    print("   â€¢ Chat API: /api/user/chat")
    print("   â€¢ Search API: /api/user/search")
    print("   â€¢ Admin Panel: /api/admin")
    
    print("âœ… Minimal RAG System ready")
    print("ğŸ¤– FLAN-T5 Small integration active")
    print("âš¡ Optimized for <1GB RAM usage")