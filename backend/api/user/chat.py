# backend/api/user/chat.py - –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –î–õ–Ø –¢–ê–ô–ú–ê–£–¢–û–í –ò ASYNC

"""
User Chat Endpoints - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ endpoints –¥–ª—è —á–∞—Ç–∞ —Å –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ú–ò –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø–ú–ò
"""

from fastapi import APIRouter, HTTPException, Depends
from typing import List, Dict, Any
import logging
import time
import asyncio

from models.requests import ChatMessage, ChatHistoryRequest
from models.responses import ChatResponse, ChatHistoryResponse, ChatHistoryItem
from app.dependencies import get_document_service, get_llm_service
from app.config import settings

router = APIRouter()
logger = logging.getLogger(__name__)

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤
chat_history: List[Dict[str, Any]] = []

# –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã
SEARCH_TIMEOUT = 10.0    # 10 —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø–æ–∏—Å–∫
LLM_TIMEOUT = 120.0      # 2 –º–∏–Ω—É—Ç—ã –Ω–∞ LLM
TOTAL_TIMEOUT = 180.0    # 3 –º–∏–Ω—É—Ç—ã –æ–±—â–∏–π —Ç–∞–π–º–∞—É—Ç

@router.post("/chat", response_model=ChatResponse)
async def chat_with_assistant(
    message: ChatMessage,
    document_service = Depends(get_document_service),
    llm_service = Depends(get_llm_service)
):
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è —á–∞—Ç–∞ —Å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –° –¢–ê–ô–ú–ê–£–¢–ê–ú–ò"""
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤–µ—Å—å endpoint –≤ —Ç–∞–π–º–∞—É—Ç
    try:
        return await asyncio.wait_for(
            _process_chat_message(message, document_service, llm_service),
            timeout=TOTAL_TIMEOUT
        )
    except asyncio.TimeoutError:
        logger.error(f"‚ùå Chat request timeout after {TOTAL_TIMEOUT}s")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∞–∂–µ –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ
        timeout_entry = {
            "message": message.message,
            "response": "‚è∞ Request timeout - please try with a shorter question",
            "language": message.language,
            "sources": [],
            "timestamp": time.time(),
            "timeout": True,
            "search_stats": {"timeout": True},
            "ai_stats": {"timeout": True}
        }
        chat_history.append(timeout_entry)
        
        if language := message.language == "uk":
            timeout_response = "‚è∞ –ó–∞–ø–∏—Ç –ø–µ—Ä–µ–≤–∏—â–∏–≤ —á–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è. –°–ø—Ä–æ–±—É–π—Ç–µ –∫–æ—Ä–æ—Ç—à–µ –ø–∏—Ç–∞–Ω–Ω—è."
        else:
            timeout_response = "‚è∞ Request timeout. Please try with a shorter question."
        
        return ChatResponse(
            response=timeout_response,
            sources=[]
        )
    except Exception as e:
        logger.error(f"‚ùå Critical chat error: {e}")
        raise HTTPException(status_code=500, detail=f"Chat service error: {str(e)}")

async def _process_chat_message(message: ChatMessage, document_service, llm_service):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —á–∞—Ç–∞ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –≤—Ä–µ–º–µ–Ω–∏"""
    
    search_results = []
    sources = []
    search_start_time = time.time()
    
    # ====================================
    # –≠–¢–ê–ü 1: –ü–û–ò–°–ö –†–ï–õ–ï–í–ê–ù–¢–ù–´–• –î–û–ö–£–ú–ï–ù–¢–û–í –° –¢–ê–ô–ú–ê–£–¢–û–ú
    # ====================================
    try:
        logger.info(f"üîç Starting search for: '{message.message[:50]}...'")
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–∏—Å–∫ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
        search_results = await asyncio.wait_for(
            document_service.search(
                query=message.message,
                limit=settings.MAX_CONTEXT_DOCUMENTS,
                min_relevance=0.3
            ),
            timeout=SEARCH_TIMEOUT
        )
        
        search_time = time.time() - search_start_time
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if search_results and isinstance(search_results, list) and len(search_results) > 0:
            sources = [result.get('filename', 'Unknown') for result in search_results]
            logger.info(f"‚úÖ Search completed: {len(search_results)} results in {search_time:.2f}s")
        else:
            logger.info(f"‚ÑπÔ∏è No relevant documents found in {search_time:.2f}s")
            search_results = []
        
    except asyncio.TimeoutError:
        search_time = time.time() - search_start_time
        logger.error(f"‚ùå Search timeout after {SEARCH_TIMEOUT}s")
        search_results = []
        
    except Exception as e:
        search_time = time.time() - search_start_time
        logger.error(f"‚ùå Search error after {search_time:.2f}s: {e}")
        search_results = []
    
    # ====================================
    # –≠–¢–ê–ü 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø AI –û–¢–í–ï–¢–ê –° –¢–ê–ô–ú–ê–£–¢–û–ú
    # ====================================
    ai_response = None
    response_text = ""
    llm_start_time = time.time()
    
    if search_results and len(search_results) > 0:
        try:
            logger.info("ü§ñ Generating AI response based on found documents...")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            context_documents = []
            for result in search_results:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                content = result.get('content', '')
                if len(content) > settings.CONTEXT_TRUNCATE_LENGTH:
                    content = content[:settings.CONTEXT_TRUNCATE_LENGTH] + "..."
                
                context_doc = {
                    "filename": result.get('filename', 'Unknown'),
                    "content": content,
                    "relevance_score": result.get('relevance_score', 0.0),
                    "metadata": result.get('metadata', {})
                }
                context_documents.append(context_doc)
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            ai_response = await asyncio.wait_for(
                llm_service.answer_legal_question(
                    question=message.message,
                    context_documents=context_documents,
                    language=message.language
                ),
                timeout=LLM_TIMEOUT
            )
            
            llm_time = time.time() - llm_start_time
            
            if ai_response and ai_response.success and ai_response.content.strip():
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –æ—Ç–≤–µ—Ç
                response_text = ai_response.content.strip()
                
                logger.info(f"‚úÖ AI response generated: {len(response_text)} chars, "
                          f"{ai_response.tokens_used} tokens, {llm_time:.2f}s")
            else:
                # AI –Ω–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
                logger.warning(f"AI response failed: {getattr(ai_response, 'error', 'Unknown error')}")
                response_text = _generate_fallback_response_with_context(
                    message.message, search_results, message.language, 
                    getattr(ai_response, 'error', 'AI response failed')
                )
                    
        except asyncio.TimeoutError:
            llm_time = time.time() - llm_start_time
            logger.error(f"‚ùå LLM timeout after {LLM_TIMEOUT}s")
            # Fallback –µ—Å–ª–∏ AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–∑-–∑–∞ —Ç–∞–π–º–∞—É—Ç–∞
            response_text = _generate_timeout_fallback_response(
                message.message, search_results, message.language
            )
            
        except Exception as e:
            llm_time = time.time() - llm_start_time
            logger.error(f"‚ùå LLM generation error after {llm_time:.2f}s: {e}")
            # Fallback –µ—Å–ª–∏ AI –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            response_text = _generate_fallback_response_with_context(
                message.message, search_results, message.language, str(e)
            )
    else:
        # –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        try:
            response_text = await asyncio.wait_for(
                _generate_no_context_response(message.message, message.language, llm_service),
                timeout=LLM_TIMEOUT
            )
        except asyncio.TimeoutError:
            logger.error(f"‚ùå No-context LLM timeout after {LLM_TIMEOUT}s")
            response_text = _generate_no_documents_found_response(message.message, message.language)
        except Exception as e:
            logger.error(f"‚ùå No-context LLM error: {e}")
            response_text = _generate_no_documents_found_response(message.message, message.language)
    
    # ====================================
    # –≠–¢–ê–ü 3: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ò–°–¢–û–†–ò–Æ
    # ====================================
    chat_entry = {
        "message": message.message,
        "response": response_text,
        "language": message.language,
        "sources": sources,
        "timestamp": time.time(),
        "search_stats": {
            "found_documents": len(search_results),
            "has_relevant_results": len(search_results) > 0,
            "search_query": message.message,
            "search_time": search_time if 'search_time' in locals() else 0.0
        },
        "ai_stats": {
            "ai_used": ai_response is not None and getattr(ai_response, 'success', False),
            "model": getattr(ai_response, 'model', 'fallback'),
            "tokens_used": getattr(ai_response, 'tokens_used', 0),
            "response_time": getattr(ai_response, 'response_time', 0.0),
            "error": getattr(ai_response, 'error', None) if ai_response and not getattr(ai_response, 'success', False) else None,
            "llm_time": llm_time if 'llm_time' in locals() else 0.0
        }
    }
    chat_history.append(chat_entry)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 100 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
    if len(chat_history) > 100:
        chat_history.pop(0)
    
    # ====================================
    # –≠–¢–ê–ü 4: –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–ê
    # ====================================
    total_time = time.time() - search_start_time
    
    if ai_response and getattr(ai_response, 'success', False):
        logger.info(f"üí¨ Chat response completed with AI: query='{message.message[:30]}...', "
                   f"sources={len(sources)}, total_time={total_time:.2f}s")
    else:
        logger.info(f"üí¨ Chat response completed with fallback: query='{message.message[:30]}...', "
                   f"sources={len(sources)}, total_time={total_time:.2f}s")
    
    return ChatResponse(
        response=response_text,
        sources=sources if sources else None
    )

def _generate_timeout_fallback_response(query: str, search_results: List[Dict], language: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ AI"""
    
    if search_results:
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        context_snippets = []
        for result in search_results[:2]:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            content = result.get('content', '')
            snippet = content[:200] + "..." if len(content) > 200 else content
            filename = result.get('filename', 'Unknown')
            relevance = result.get('relevance_score', 0.0)
            
            context_snippets.append(f"üìÑ {filename} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance:.1%}): {snippet}")
        
        context = "\n\n".join(context_snippets)
        
        if language == "uk":
            response_text = f"""‚è∞ **AI –∞—Å–∏—Å—Ç–µ–Ω—Ç –ø–µ—Ä–µ–≤–∏—â–∏–≤ —á–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è**

**–í–∞—à–µ –ø–∏—Ç–∞–Ω–Ω—è:** {query}

üìö –ó–Ω–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —É –±–∞–∑—ñ –∑–Ω–∞–Ω—å:

{context}

üîÑ **–°—Ç–∞—Ç—É—Å:** AI –º–æ–¥–µ–ª—å –∑–∞–π–Ω—è–ª–∞ –∑–∞–±–∞–≥–∞—Ç–æ —á–∞—Å—É –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.

üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
‚Ä¢ –°–ø—Ä–æ–±—É–π—Ç–µ –∫–æ—Ä–æ—Ç—à–µ —Ç–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ—à–µ –ø–∏—Ç–∞–Ω–Ω—è
‚Ä¢ –ü–µ—Ä–µ—Ñ—Ä–∞–∑—É–π—Ç–µ –∑–∞–ø–∏—Ç –ø—Ä–æ—Å—Ç—ñ—à–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑–∞–º—ñ—Å—Ç—å –¥–æ–≤–≥–∏—Ö —Ä–µ—á–µ–Ω—å

üîß **–î–ª—è –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞:** –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞ GPTQ –º–æ–¥–µ–ª—å"""
        else:
            response_text = f"""‚è∞ **AI Assistant Timeout**

**Your Question:** {query}

üìö Found {len(search_results)} relevant documents in knowledge base:

{context}

üîÑ **Status:** AI model took too long to respond.

üí° **Recommendations:**
‚Ä¢ Try a shorter, more specific question
‚Ä¢ Rephrase using simpler language
‚Ä¢ Use keywords instead of long sentences

üîß **For administrator:** Check GPTQ model load"""
        
    else:
        # –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Ç–∞–π–º–∞—É—Ç AI
        if language == "uk":
            response_text = f"""‚è∞ **–¢–∞–π–º–∞—É—Ç AI —Ç–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤**

**–í–∞—à–µ –ø–∏—Ç–∞–Ω–Ω—è:** {query}

‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —É –±–∞–∑—ñ –∑–Ω–∞–Ω—å.
‚è∞ AI –º–æ–¥–µ–ª—å —Ç–∞–∫–æ–∂ –ø–µ—Ä–µ–≤–∏—â–∏–ª–∞ —á–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è.

üí° **–°–ø—Ä–æ–±—É–π—Ç–µ:**
‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ñ–Ω—à—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
‚Ä¢ –°—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ—Å—Ç—ñ—à–µ
‚Ä¢ –î–æ–¥–∞—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ —á–µ—Ä–µ–∑ –∞–¥–º—ñ–Ω –ø–∞–Ω–µ–ª—å"""
        else:
            response_text = f"""‚è∞ **AI Timeout and No Documents**

**Your Question:** {query}

‚ùå No relevant documents found in knowledge base.
‚è∞ AI model also exceeded timeout.

üí° **Try:**
‚Ä¢ Using different keywords
‚Ä¢ Simplifying your question
‚Ä¢ Adding relevant documents via admin panel"""
    
    return response_text

def _generate_no_documents_found_response(query: str, language: str) -> str:
    """–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –∫–æ–≥–¥–∞ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    
    if language == "uk":
        return f"""üîç **–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É –¥–ª—è:** "{query}"

‚ùå –ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —É –±–∞–∑—ñ –∑–Ω–∞–Ω—å.

ü§ñ AI-–ø–æ–º—ñ—á–Ω–∏–∫ —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π.

üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**
‚Ä¢ –°–ø—Ä–æ–±—É–π—Ç–µ —ñ–Ω—à—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –±—ñ–ª—å—à –∑–∞–≥–∞–ª—å–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏
‚Ä¢ –î–æ–¥–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏ —á–µ—Ä–µ–∑ –∞–¥–º—ñ–Ω –ø–∞–Ω–µ–ª—å
‚Ä¢ –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ, –∫–æ–ª–∏ AI –±—É–¥–µ –¥–æ—Å—Ç—É–ø–Ω–∏–π"""
    else:
        return f"""üîç **Search Results for:** "{query}"

‚ùå Unfortunately, no relevant documents found in knowledge base.

ü§ñ AI assistant temporarily unavailable.

üí° **Recommendations:**
‚Ä¢ Try different keywords
‚Ä¢ Use more general terms  
‚Ä¢ Add documents via admin panel
‚Ä¢ Try again later when AI is available"""

def _generate_fallback_response_with_context(query: str, search_results: List[Dict], 
                                           language: str, error: str = None) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç fallback –æ—Ç–≤–µ—Ç –∫–æ–≥–¥–∞ AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –µ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–∏–ø–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    context_snippets = []
    for result in search_results[:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        content = result.get('content', '')
        snippet = content[:300] + "..." if len(content) > 300 else content
        filename = result.get('filename', 'Unknown')
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        match_type = result.get('search_info', {}).get('match_type', 'unknown')
        relevance = result.get('relevance_score', 0.0)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if match_type == "exact":
            if language == "uk":
                match_description = "üìç –¢–æ—á–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è"
            else:
                match_description = "üìç Exact match"
        elif match_type == "semantic":
            if language == "uk":
                match_description = "üîç –°–µ–º–∞–Ω—Ç–∏—á–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è"
            else:
                match_description = "üîç Semantic match"
        else:
            if language == "uk":
                match_description = f"üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å: {relevance:.1%}"
            else:
                match_description = f"üìä Relevance: {relevance:.1%}"
        
        context_snippets.append(f"üìÑ {filename} ({match_description}): {snippet}")
    
    context = "\n\n".join(context_snippets)
    
    if language == "uk":
        response_text = f"""üîç –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É –¥–ª—è –∑–∞–ø–∏—Ç–∞–Ω–Ω—è: "{query}"

üìö –ó–Ω–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —É –±–∞–∑—ñ –∑–Ω–∞–Ω—å:

{context}

‚ö†Ô∏è AI-–ø–æ–º—ñ—á–Ω–∏–∫ —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π"""
        
        if error:
            response_text += f" (–ø—Ä–∏—á–∏–Ω–∞: {error})"
        
        response_text += """.

üí° –ù–∞ –æ—Å–Ω–æ–≤—ñ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –≤–∏ –º–æ–∂–µ—Ç–µ:
‚Ä¢ –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –ø–æ–≤–Ω–∏–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —á–µ—Ä–µ–∑ –∞–¥–º—ñ–Ω –ø–∞–Ω–µ–ª—å
‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç–∏ –∑–∞–ø–∏—Ç –¥–ª—è –∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤  
‚Ä¢ –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –ø–æ—à—É–∫ —ñ–Ω—à–∏–º–∏ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏

üîß –î–ª—è –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Å—Ç–∞—Ç—É—Å GPTQ –º–æ–¥–µ–ª–∏"""
    else:
        response_text = f"""üîç Search results for query: "{query}"

üìö Found {len(search_results)} relevant documents in the knowledge base:

{context}

‚ö†Ô∏è AI assistant temporarily unavailable"""
        
        if error:
            response_text += f" (reason: {error})"
            
        response_text += """.

üí° Based on the found documents, you can:
‚Ä¢ Review the full document text through the admin panel
‚Ä¢ Refine your query for better results
‚Ä¢ Try searching with different keywords

üîß For administrator: check GPTQ model status"""
    
    return response_text

async def _generate_no_context_response(query: str, language: str, llm_service) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∫–æ–≥–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å AI –æ—Ç–≤–µ—Ç –¥–∞–∂–µ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è) —Å —Ç–∞–π–º–∞—É—Ç–æ–º
    try:
        ai_response = await asyncio.wait_for(
            llm_service.answer_legal_question(
                question=query,
                context_documents=[],
                language=language
            ),
            timeout=60.0  # 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π
        )
        
        if ai_response and ai_response.success and ai_response.content.strip():
            # AI —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if language == "uk":
                return f"""ü§ñ –í—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–≥–∞–ª—å–Ω–∏—Ö –∑–Ω–∞–Ω—å:

{ai_response.content}

‚ö†Ô∏è –ó–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É: —Ü—è –≤—ñ–¥–ø–æ–≤—ñ–¥—å –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ –∑–∞–≥–∞–ª—å–Ω–∏—Ö –∑–Ω–∞–Ω–Ω—è—Ö AI, –∞ –Ω–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —É –≤–∞—à—ñ–π –±–∞–∑—ñ –∑–Ω–∞–Ω—å. –î–ª—è –±—ñ–ª—å—à —Ç–æ—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó —Ä–µ–∫–æ–º–µ–Ω–¥—É—î–º–æ –¥–æ–¥–∞—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ —á–µ—Ä–µ–∑ –∞–¥–º—ñ–Ω –ø–∞–Ω–µ–ª—å."""
            else:
                return f"""ü§ñ Response based on general knowledge:

{ai_response.content}

‚ö†Ô∏è Note: This response is based on the AI's general knowledge, not on documents in your knowledge base. For more accurate information, we recommend adding relevant documents through the admin panel."""
        
    except asyncio.TimeoutError:
        logger.debug(f"AI general knowledge response timeout for: {query}")
    except Exception as e:
        logger.debug(f"AI general knowledge response failed: {e}")
    
    # Fallback –µ—Å–ª–∏ AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω —Å–æ–≤—Å–µ–º
    return _generate_no_documents_found_response(query, language)

# –û—Å—Ç–∞–ª—å–Ω—ã–µ endpoints –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...

@router.get("/chat/history", response_model=ChatHistoryResponse)
async def get_chat_history(request: ChatHistoryRequest = ChatHistoryRequest()):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π
        recent_history = chat_history[-request.limit:] if chat_history else []
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        formatted_history = []
        for entry in recent_history:
            formatted_entry = ChatHistoryItem(
                message=entry["message"],
                response=entry["response"],
                language=entry["language"],
                sources=entry.get("sources"),
                timestamp=entry.get("timestamp")
            )
            formatted_history.append(formatted_entry)
        
        return ChatHistoryResponse(
            history=formatted_history,
            total_messages=len(chat_history)
        )
        
    except Exception as e:
        logger.error(f"Chat history error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get chat history: {str(e)}")

@router.delete("/chat/history")
async def clear_chat_history():
    """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–æ–≤"""
    try:
        global chat_history
        old_count = len(chat_history)
        chat_history.clear()
        
        logger.info(f"Chat history cleared: {old_count} messages removed")
        
        return {
            "message": f"Cleared {old_count} chat messages",
            "remaining": len(chat_history)
        }
        
    except Exception as e:
        logger.error(f"Clear history error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to clear chat history: {str(e)}")

@router.get("/chat/stats")
async def get_chat_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —á–∞—Ç–æ–≤ —Å AI –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —è–∑—ã–∫–∏
        languages = {}
        sources_used = 0
        successful_searches = 0
        total_search_results = 0
        ai_responses = 0
        total_tokens = 0
        total_ai_time = 0.0
        timeouts = 0
        
        for entry in chat_history:
            lang = entry.get("language", "unknown")
            languages[lang] = languages.get(lang, 0) + 1
            
            if entry.get("sources"):
                sources_used += 1
            
            if entry.get("timeout", False):
                timeouts += 1
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–∏—Å–∫–∞
            search_stats = entry.get("search_stats", {})
            if search_stats.get("has_relevant_results", False):
                successful_searches += 1
                total_search_results += search_stats.get("found_documents", 0)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º AI —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            ai_stats = entry.get("ai_stats", {})
            if ai_stats.get("ai_used", False):
                ai_responses += 1
                total_tokens += ai_stats.get("tokens_used", 0)
                total_ai_time += ai_stats.get("response_time", 0)
        
        return {
            "total_messages": len(chat_history),
            "languages": languages,
            "messages_with_sources": sources_used,
            "successful_searches": successful_searches,
            "success_rate": (successful_searches / len(chat_history) * 100) if chat_history else 0,
            "average_sources_per_message": sources_used / len(chat_history) if chat_history else 0,
            "average_results_per_successful_search": total_search_results / successful_searches if successful_searches > 0 else 0,
            
            # AI —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            "ai_responses": ai_responses,
            "ai_usage_rate": (ai_responses / len(chat_history) * 100) if chat_history else 0,
            "total_tokens_used": total_tokens,
            "average_tokens_per_ai_response": total_tokens / ai_responses if ai_responses > 0 else 0,
            "total_ai_time": total_ai_time,
            "average_ai_response_time": total_ai_time / ai_responses if ai_responses > 0 else 0,
            
            # –¢–∞–π–º–∞—É—Ç—ã
            "timeouts": timeouts,
            "timeout_rate": (timeouts / len(chat_history) * 100) if chat_history else 0
        }
        
    except Exception as e:
        logger.error(f"Chat stats error: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get chat stats: {str(e)}")

@router.get("/chat/timeout-test")
async def test_timeout_behavior():
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∞–π–º–∞—É—Ç–æ–≤"""
    try:
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω—É—é –æ–ø–µ—Ä–∞—Ü–∏—é
        await asyncio.sleep(5)
        
        return {
            "message": "Timeout test completed",
            "duration": "5 seconds",
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Timeout test error: {e}")
        return {
            "message": "Timeout test failed",
            "error": str(e)
        }